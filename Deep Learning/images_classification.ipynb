{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 1,
    "id": "kr9vAeEQlRVG"
   },
   "source": [
    "# Домашнее задание 2. Классификация изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 3,
    "id": "BxX49gLclRVJ"
   },
   "source": [
    "In this task we will need to train an image classifier. We will work with a dataset, the name of which we will not disclose. You can look at the images in the dataset yourself. It contains 200 classes and about 5 thousand pictures for each class. Classes are numbered, as it is easy to guess, from 0 to 199. You can download the dataset here [here](https://yadi.sk/d/BNR41Vu3y0c7qA).\n",
    "\n",
    "The structure of the dataset is simple -- there are directories train/ and val/, where the training and validation data are located. In train/ and val/ there are directories corresponding to the classes of images, where the images themselves lie.\n",
    " \n",
    "__Job__. You should perform two tasks\n",
    "\n",
    "1) Achieve an accuracy **on validation of at least 0.44**. It is **forbidden** to use pre-trained models and image resizing in this task. 5 points\n",
    "\n",
    "2) Achieve accuracy **at least 0.83** on validation. It is allowed to resize and use pretrain in this task. 5 points\n",
    "\n",
    "Write a brief report about your experiments. What worked and what didn't work? Why did you decide to do it this way and not the other way around? Be sure to provide references to other people's code if you use it. Be sure to refer to articles / blogposts / questions on stackoverflow / youtubers' videos / courses / tips from Uncle Vasya and other additional materials if you use them. \n",
    "\n",
    "Your code must necessarily pass all `asserts` below.\n",
    "\n",
    "__Use of external data for training is strictly prohibited in both assignments. It is also prohibited to train on the validation sample__.\n",
    "\n",
    "\n",
    "__Grading Criteria__: The score is calculated using a simple formula: `min(10, 10 * your accuracy / 0.44)` for the first assignment and `min(10, 10 * (your accuracy - 0.5) / 0.34)` for the second assignment. Grades are rounded to the tenths using arithmetic rules.\n",
    "\n",
    "\n",
    "__Tips and Directions__:\n",
    " - You will probably need to do a lot of googling about classification and how to make it work. That's fine, everyone googles. But don't forget that you need to be ready to be responsible for the rolled up code :)\n",
    " - Use augmentations. Use the `torchvision.transforms` module or the [augmentations] library(https://github.com/albumentations-team/albumentations) for this purpose.\n",
    " - You can train from scratch or filetune (depending on the job) models from `torchvision`.\n",
    " - We recommend that you first write a dataset class (or use the `ImageFolder` class) that returns images and their corresponding classes, and then trayne functions using the templates below. However, we don't force you to do this. If you're not comfortable doing so, you can write code in a style you're comfortable with. But be aware that excessive modification of the templates below will increase the number of questions to your code and increase the probability of being called for defense :)\n",
    " - Validate- Track errors as early as possible to avoid wasting time.\n",
    " - To debug your code quickly, try to train on a small part of the dataset (say, 5-10 images just to make sure that the code runs). When you realize that you can debug everything, move on to training on the whole dataset\n",
    " - Make exactly one change in the model/augmentation/optimizer for each run to understand what and how it affects the result.\n",
    " - Fix random seed.\n",
    " - Start with simple models and gradually move to complex models. Training easy models saves a lot of time.\n",
    " - Set a schedule on the learning rate. Decrease it when the validation loss stops decreasing.\n",
    " - We advise you to use a GPU. If you don't have one, use google colab. If you don't feel comfortable using it on a regular basis, write and debug all code locally on CPU and then run the already written notebook in colab. The author's solution to the problem achieves the required accuracy in colab in 15 minutes of training.\n",
    " \n",
    "Good luck & have fun! :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "EWT3aFU9XmLJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import pandas as pd\n",
    "from torchvision.transforms import v2\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "47YPLjDL-Mtv"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(505505)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RytEDW0ylRVN"
   },
   "source": [
    "## Task 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HZECedTvepi"
   },
   "source": [
    "### What can help get a 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOioHGEiveso"
   },
   "source": [
    "1. use all possible optimization methods and experiment with them.\n",
    "2. Selection of learning rate. An example from the last seminar on how to do this: [How to find lr](https://pytorch-lightning.readthedocs.io/en/1.4.5/advanced/lr_finder.html)\n",
    "\n",
    "```\n",
    "  trainer = pl.Trainer(accelerator=“gpu”, max_epochs=2, auto_lr_find=True) \n",
    "\n",
    "  trainer.tune(module, train_dataloader, eval_dataloader)\n",
    "\n",
    "  trainer.fit(module, train_dataloader, eval_dataloader))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "3. data augmentation. [Documentation (useful)](https://pytorch.org/vision/main/transforms.html), and [albumentation library](https://towardsdatascience.com/getting-started-with-albumentation-winning-deep-learning-image-augmentation-technique-in-pytorch-47aaba0ee3f8)\n",
    "4. Model architecture selection. \n",
    "5. You can handwrite your own model in YourNet, or you can import an untrained mesh of a known architecture from the torchvision.models module. One way to do this is to: \n",
    "\n",
    "  * `torchvision.models.resnet18(pretrained=False, num_classes=200).to(device)`.\n",
    "  * Documentation on possible models and how you can take them: [Documentation (useful)](https://pytorch.org/vision/stable/models.html)\n",
    "6. Properly normalize data when creating, example [youk, but here and the whole guide from and to](https://www.pluralsight.com/guides/image-classification-with-pytorch)\n",
    "7. Model Checkpointing. Save your progress (models) so that when something goes wrong you can start from there or just reproduce your results of the model you trained. \n",
    " * Example of how you can with wandb here: [Save the best models in wandb](https://docs.wandb.ai/guides/integrations/lightning)\n",
    " * A simple example is: [Save models to pytorch doc](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYePsQgNRB-n"
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image size: 64 x 64\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = 'dataset/train/class_000/00001.jpg'\n",
    "image = Image.open(image_path)\n",
    "width, height = image.size\n",
    "print(f'Original image size: {width} x {height}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.ColorJitter(hue=0.05, saturation=0.05),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(),\n",
    "    v2.RandomRotation(20),\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True ),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_val = v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True ),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 5,
    "id": "QEdDQtHdlRVO"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_transform = transforms\n",
    "val_transform = transforms_val\n",
    "\n",
    "train_dataset = ImageFolder('dataset/train', transform=train_transform)\n",
    "val_dataset = ImageFolder('dataset/val', transform=val_transform)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=4, persistent_workers=True ) \n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, persistent_workers=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 6,
    "id": "mrg4Yj0VlRVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests passed\n"
     ]
    }
   ],
   "source": [
    "# Just very simple sanity checks\n",
    "assert isinstance(train_dataset[0], tuple)\n",
    "assert len(train_dataset[0]) == 2\n",
    "assert isinstance(train_dataset[1][1], int)\n",
    "print(\"tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOuM0EEYj7Ml"
   },
   "source": [
    "### Lets take a look at the pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DeuB0YC3LYRm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGfCAYAAAD22G0fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7fklEQVR4nO3de3iU5Zk/8O8oMBgIEVRy0AgRAshBRUAkHkARLB62LK1V8YBra0VQobaLAq0GVxPEXYr9gekGFaEW2W0VStcDpCqhSqkRoQYQRIkQgZiimISDicLz+4OL0WTuL/JCwjOZfD/XlevS7zx5532TmdxM5s79hJxzDiIiIh6c4PsERESk6VIREhERb1SERETEGxUhERHxRkVIRES8URESERFvVIRERMQbFSEREfFGRUhERLxRERIREW+aNdSBn3zySTz++OPYsWMHevTogRkzZuCSSy75zs87cOAAtm/fjsTERIRCoYY6PRERaSDOOVRVVSEtLQ0nnPAdr3VcA1iwYIFr3ry5mz17tlu/fr0bN26ca9WqlduyZct3fm5paakDoA996EMf+mjkH6Wlpd/5Mz/kXP0PMO3fvz/OP/985OXlRbKzzz4bw4cPR25u7mE/t6KiAieffHJ9n5JfvUl+Psn/YWTv1NO5xLoWJP8hyb8m+f8GuM8hJG9L8jQju5Gs7UbyL0i+ieTpRvZPsrYXyf+H5Ncb2d/I2nkkZ+fCvoY7jewusnYryU8j+feM7PtkLbvOWHIKyScY2Xqy9iySLyK59Xizvq4AMIbkAL744gskJSXxBWiAX8fV1NRg1apVeOCBB2rlQ4cOxYoVK6LWV1dXo7q6OvL/VVVV9X1K/p1IcvYDt8F+SdoIsN/Asq9Vfbyr2TzgfYaNrDVZ24bkB0jeiuSJRrYv4H2eFGA9Ow/2NQn6NbQe4wlkLTtvtt66nsb8nGKPcevrwr7eLUnOfjZZ30/2fTiMI3lLpd4bE3bu3In9+/cjOTm5Vp6cnIyysrKo9bm5uUhKSop8pKdbJVhEROJRg3XH1a2AzjmzKk6cOBEVFRWRj9LS0oY6JRERiTH1/iL11FNPxYknnhj1qqe8vDzq1REAhMNhhMPW7zfiyDaSX0ryjka2naz9KuC5lBvZ/oDHaEjsV0nsvZ8OJO9iZF+StR+SvB3Js4yM/WrsUZLfTvLOJD/VyNj5MTcHWNsp4LFfJjl7at9qZPlk7WCSdyT5FiNj79ldSfJfktwH9n7bDCN7iqxdS/JfkPy/jcx63NeDen8l1KJFC/Tp0wcFBQW18oKCAmRlNdBViIhIo9Qgb9fdd999uOWWW9C3b18MGDAA+fn52Lp1K0aPHt0QdyciIo1UgxSh66+/Hp999hkefvhh7NixAz179sTLL7+MDh3Y705ERKQparDGxTFjxmDMmMM0kIuISJOn2XEiIuJNg0xMOBaVlZUH/8I2CdF/uMg6kKpJHuvYKD3rDxPZHwO2J7nVBQcAq42M/UW6DyeTnE0e+JzkrMvOEnQaxclG9muylv0G+iOS9yP56Yc7oTqsTrqg2HQF67F5GO9fZbVZAWeH7owOryIHYZ2Ez5Pc6jCsJGtZ1yXrXL2F5LHiByRn37eZJF9oZKy79A5+OhUVFWjT5vBPRr0SEhERb1SERETEGxUhERHxRkVIRES8id3ZslWIbkxgb9pab8Jvrt/TaRB/Jbk12ZZdu7WtwOHEUhOChW1DwEbUXEByqwGDjTi6geSsEcYa8zOLrGVvCLPtPdgz0mpM6U7WsgndQf7JyR5vAUcfnb3YaEAA8IQbGZWNC83/7vP6NjbOx/res+/D28HuMuZZ1w4A15D8igDHXhnwXI6QXgmJiIg3KkIiIuKNipCIiHijIiQiIt6oCImIiDex2x1nid4T76CORsbGpbB90tnGZh8c7oQaiLXJHOtMaaCOlQbXl+TXBTxOYYC1QbrdAD4SyNo0jY0VYtfzNMn/SPKfGllbspZhzx/rn6JnkbXs+cB+kpCuwXH9jE64R8gxJpOcjdCxNrBbQtb+mOTsMcF838j+FPAY9YE9DtnPPfYYtzYdVHeciIjEGxUhERHxRkVIRES8URESERFvVIRERMSb2O2O+x6i52WxjjdrJhibqdaR5NYmToCf7rh4c6aRWR1MAP++WR1pADCQ5NZjpZisXU5ytpGcteEZW9uT5GwzNTbbj3V3Wdj8PTY7z9pzjD3XuthxB5JvYd1a1oZ0/0rWPmXHn/xumJmfMeCV6JB1gbHvG5tJONSOQ4uiM1d39uXxwDa5/D+Ss+fP94zsl8FP50jolZCIiHijIiQiIt6oCImIiDcqQiIi4o2KkIiIeBO73XGtAbSok1WStdbOqqz7aAXJfcxgY/PTNhjZ7oY8kXqSSvJfGBnr4qkiOft+biO5NVOOdcF1IvmVJP9vIwvaRXkHydmOwNYz1eowA/iurWx+mLXrqPUYBOj8vS1s51LW1cc6+Cykw+6MN4wuOACn/y0622Z1NAJAFskf/c6zqsVZc/ysrlCgYXc3Zt+3sSRnOwLProdzOUJ6JSQiIt6oCImIiDcqQiIi4o2KkIiIeBNyzjnfJ/FtlZWVSEpKOvhGWrjOjdZ4EQD41MhWk7WNdRO4xuAGkt9uZGyEDMO+9w+S3HrjuzNZy95Un0Hyf5Dccj/J2RiVdQGOzTxG8sEkt95UZ5vrTSA5+5qwRhPr+89GyLCRWsxHRkYaWN56YpKZX9Qpx/4ENoboZSNbl2Cv7bGXHKThPON+Zua3v/lr+xMGGVk7cvB/8vutqKhAmzbsyXuQXgmJiIg3KkIiIuKNipCIiHijIiQiIt6oCImIiDexO7ZnN4CaOhnbaMoaJcI6gdQd13DYaBQL26SOjZYpIjlrvLE68oKOKCEbtd27/UdR2W/S/tdezDrViHkuycx/hYqojOyvRi+Hfalyjez3pAvuKnKMX75GbmDjeazuVda9yEZtnU1ya9wSGTd00aN2F9wTH9ndZONCpJvsZCPz0AXH3M7OO4gfWo8UAHkfGmENgN8d0WH1SkhERLxRERIREW9UhERExBsVIRER8UZFSEREvInd2XGWS9gnGRnrvvoi+DlJHazji82Wsrrm2GZ0bFMutqkd68izmptI5939Lw2zb9hhDVUDHkubT+702N1Cno3WODRrL0eA79HH1luNas3J2g4k/3Cnnf/wVDu3vrKXINNce+vVm+yDjCcnY80CvJCsZcaR/Dd2bP0YDSWG7MVsVuGO7zyr+sc2Vwyyqd25xvy9/dXA2v/S7DgREYltKkIiIuKNipCIiHijIiQiIt6oCImIiDeBu+OWL1+Oxx9/HKtWrcKOHTuwcOFCDB8+PHK7cw5TpkxBfn4+du3ahf79+2PWrFno0aPHER3/sN1xEhteJ7nVwgXYLVVWR+PhsLlipJsu6/robAvZ/XPbeQHPpSGR3WlDz0dnPckhikmnWgLpVLMmnJ1Ojs2aGoOy9hxlm+2ynG1yaj0k7iNrp5MGNvoYZ/MrL4qO3Br7R2voUXKnrH2RdOQFwbouf2ftCAsguWN09umR/QivpUG64/bs2YNzzz0XM2fONG+fNm0apk+fjpkzZ6KoqAgpKSkYMmQIqqrYPr8iItJUBZ6iPWzYMAwbZv9dhXMOM2bMwOTJkzFixAgAwNy5c5GcnIz58+fjzjvvjPqc6upqVFdXR/6/sjLoP5FFRKSxqtf3hEpKSlBWVoahQ78ZMh8OhzFw4ECsWGHPY8/NzUVSUlLkIz09vT5PSUREYli9FqGysjIAQHJycq08OTk5cltdEydOREVFReSjtLS0Pk9JRERiWINsahcK1X7jzTkXlR0SDocRDocb4jRERCTG1WsRSklJAXDwFVFqamokLy8vj3p1JI3Y5ST/J8mtrh/21l9vkn9JcjIPbsWNRriAHCOWkHN0LaOzYjZPj3xN9uSPNvPX8duobPAe+xjtWtk5e0j8keT1sefoxgBrp5OOQbDe4M0k/w+SG52X7B/ebzl719Z+5MF/8q23mvnevuRcDBvIXLp/I1vlzjFOPXm3vfbT1kd+HpZ6/XVcRkYGUlJSUFBQEMlqampQWFiIrKys+rwrERGJA4FfCe3evRsffvjNnuIlJSVYs2YN2rVrhzPPPBPjx49HTk4OMjMzkZmZiZycHCQkJGDkyJH1euIiItL4BS5C77zzDi677LLI/99338E/Axs1ahSeffZZTJgwAfv27cOYMWMif6y6dOlSJCay+eUiItJUBS5CgwYNMvfOOCQUCiE7OxvZ2dnHcl4iItIENK5N7WIFeyOOvHHXZKwhufVG+YdGdjjWzmsA32VtuZEF2agroG4fdTfzDT9Zb3/C7eRAr5F8YHTUz36/GkU3kWOwOT+/jI7uID8V8nG3mV8Ae4IK+/2HNRUnm6xlOZu409XISK8GVq8kN7C5RZ8HWD+PrP05yV+y44qrrCFHQJXR3jGIPNwetB+e+BVpwLj6rOhsrb0Uy//NCGsAzG+gsT0iIiL1RUVIRES8URESERFvVIRERMQbFSEREfFG3XESHBv1V01ya7zIYLKW7WDGtqMK8udnbGjH2QGOAQDGCJ02Z6WYSyvX24N70f0MM+5F2v1a4q2obOMb9qETyUZ/n9z1tH0D7olKKslgnTZYaObfw7+a+RJyj3ghOrr3B/ZSNp6HHjsIMs6GbjB3boBjsy6479lxuyF2PoMc5mXj+fY8eW5eQLrmikg3ZnPj+fmV3RiJ51+P3tFvb+XX+HHS39UdJyIisU1FSEREvFEREhERb1SERETEGxUhERHxRt1xh3Qh+QfH9SziUw8jG0/WdiM56YJrR7qVrD3wTkOmubYK9u5wn6OEnMzxN9zIWh6w176Ra+cPkllzY9KP/DzYyL+TyL9nr4V9klbH29437WM3v9jOv8ojJ2PtDcdm8o0l+QqS55N8eIBj1NMMw3nGT+52ZC0bG9jRmBsIwP4ask0UrY3+9gPYoNlxIiIS41SERETEGxUhERHxRkVIRES8URESERFv1B13yFCSLz2uZxHciSTff1zP4iAy5Ktbl+idIXuSPp6u6Gzmf4M9EK0N0sz8JWOb13boZK5NRHsz/9CY13aQNSeOzIgLqBfJrbFi55G1t5A8RDoM5/3dOAbZidO+duArsndpi2mkw9CaETjQ7l5Eu0vN+JnuT5m5tdFnKET2Yb3EjrGN5C+S3OjSnIePzaUdyHxA+yq50OXR13TDr+y1C/7FzptPs/OvxgQ4Eetn59cAXld3nIiIxDgVIRER8UZFSEREvFEREhERb9SY0Ni1JvnuYz90iDQazOxib8j2Mj4x85eMrBuiN8ICgE4YaOZb8bl9Mqg003KjMaE9PjXXnod9Zn4m2dhtq5GdZq4EeQsauJfk8YbtUbjGyC5g78y/TfLHSX5jdCNMzal7zKXNySFCpOOnA5kf9R+4PSq7dfiv7YPbPRxU5+ft/MN/GOHPyEHspxVIvw+w4PDnVIu1aeV+AKvVmCAiIjFORUhERLxRERIREW9UhERExBsVIRER8UbdcfHqBpIbzT23kI26yJQXtIU90+UksiPdPqNHrJy0CH1E5qVsp3NU7M62RGyJypqT7r2u5MjlJL/cyO4ja4Efk/xp+hnxhT2Xo3dNKyIdkBfkvWcfgrW2GTvvnT7VHgm0resm+xjs28PG/GQbmd2MCdxJcrJBI1aR/N+NjGzSd+kPWpj58lANOXj9UHeciIjENBUhERHxRkVIRES8URESERFvVIRERMQbdcc1dqkkJ10ysybfHZX90+gkA4CP8JGZV5G7bEk2h/sSzaKyDbT3zO6QakdaodqS7rhdxiZza0vte/xzup3zTcauNbLlZC0bFFY/m+DFk9Cz5Ib/JPna6BlxAIA3jZl/heQYq0nOZq31JPkKI2NNYf1IvoTkWST/v+jo8ifsr8nrIXsOYn2Y6l6Nyr6s3IPspB+oO05ERGKbipCIiHijIiQiIt6oCImIiDcqQiIi4o264xq7sB1P/TLXzNOMOW7/D38013Yj+4J+RfbL3IgiM68yuu/ak66xTuTYLUk33RsH7NlXk4x/XrGxX50R3TF40JMkt2bkrSdrxWL1aqWTGWmfsyGGrLPN6qbLIWtfI/lgktvNmDBHG95F1g4g+d9IfiXJl5K8geS79838p6Gz6eeoO05ERGKaipCIiHijIiQiIt6oCImIiDeBilBubi769euHxMREtG/fHsOHD8fGjRtrrXHOITs7G2lpaTjppJMwaNAgrFu3rl5PWkRE4kP0UK/DKCwsxNixY9GvXz98/fXXmDx5MoYOHYr169ejVatWAIBp06Zh+vTpePbZZ9GlSxc88sgjGDJkCDZu3IjERNbmIt+JzIi7ZfskM99Ous/6GYOoEsk0uG2kFagKxSS3tTUeZp3otpP2jKtdZPWb5J9RyTjDSO2dVUFm5AEHSK5OuGNlTTj7vC9Z3Jrkb5J8uJHZYw2BziRvR/Kfkfx/jGwnWTuR5CtJfpy74ABgk9E0nRkKNch9BSpCr75ae1DdnDlz0L59e6xatQqXXnopnHOYMWMGJk+ejBEjRgAA5s6di+TkZMyfPx933sn2tRURkabomN4TqqioAAC0a3fwnw0lJSUoKyvD0KFDI2vC4TAGDhyIFSusMbNAdXU1Kisra32IiEjTcNRFyDmH++67DxdffDF69jw437ys7OB4+uTk5Fprk5OTI7fVlZubi6SkpMhHejqZqy8iInHnqIvQ3Xffjffeew/PP/981G2hOr87dM5FZYdMnDgRFRUVkY/SUrLpi4iIxJ1A7wkdcs8992Dx4sVYvnw5zjjjmzeAU1JSABx8RZSa+s076eXl5VGvjg4Jh8MIh8nsGYm4b/sMcovdgHAzfmrmefhdVLYRG8y12/GhmZ9JNp7rR97NbWbMV9kCe9zOeWYKTCB5Mh25s9bIWGPCKySX48m5DDPvWFpi5lveJgfqZS0ma39C8sUkf5Hk1k9Sthkfe2v8TJIHwZo4dtvxH9wmMzebEC4kx2YNFUco0Csh5xzuvvtuvPjii3j99deRkVH7QZORkYGUlBQUFBREspqaGhQWFiIri20PKCIiTVWgV0Jjx47F/Pnz8ac//QmJiYmR93mSkpJw0kknIRQKYfz48cjJyUFmZiYyMzORk5ODhIQEjBw5skEuQEREGq9ARSgvLw8AMGjQoFr5nDlzcNtttwEAJkyYgH379mHMmDHYtWsX+vfvj6VLl+pvhEREJEqgInQkuz6EQiFkZ2cjOzv7aM9JRESaCM2OExERb46qO06Ovw6k86wtOpn5s3jGzE835pc0I11w55Fz6UvOpR++NvO2iP5VbCd8Zq7tDbahYT+S29cJWN2Yp5C19rnI8bUWpAvuQfIJ15Hc+tb3JGunkdx+WgH239zb3XesF6s+uuAY0gX3GumCGxzKPPJjH2MXHKNXQiIi4o2KkIiIeKMiJCIi3qgIiYiINypCIiLijbrjjgc2c8kepwf8KTpai/8zl35E5rjdjHFmvt3YHu5qsnldS3LsXXjXzNeYKfAfRtaOznxj/kjy00ludwNJ7GINbO/PsfMryKzjbVazJxtPeQvJl5PcbgDFE/dEd5mN6xTwMcg29XuH5NY1kbsM1AV3nOmVkIiIeKMiJCIi3qgIiYiINypCIiLijYqQiIh4o+644+Ejkls7QAJmN0wVisyl38cPzXwrXjLzlsZOrM3wF3MtG5/VnOR3BJr7NpOsDaqsno4jsWopybfVxwy2yXY875HzzfzWN+3O0HFpATrhTiS53YzKu+as9X2O/DRihV4JiYiINypCIiLijYqQiIh4oyIkIiLeqAiJiIg36o47Hv5Jcjb27LXoaF0fe9fJ9mRn0Q6k9e7nHyyLyg50sU8jZMeHEd15F59aGFkNWZtBcvv7KdEub8iDP2rHtz5qd8FR1nNoO1m7n+SdSf4pya3dXBshvRISERFvVIRERMQbFSEREfFGRUhERLxRY8LRuITkfyX5DST/T5Lvjo6Kn7aXFm//zMxd1XAzf73LsqgseAMCY2+Ox9+hbaw6GFk5WZvYkCfSJJzWkM0dZ5F8G8lZ780HRsbGCtn7TQKrSc42v/wHyY+zdv8VnbkvgV1kJFJdeiUkIiLeqAiJiIg3KkIiIuKNipCIiHijIiQiIt6EnHPO90l8W2VlJZKS2OZoMe4xkt8f8DipRvYrsnZMwGPfFR25JwMeI6ZYI3QAPkYnCPY4bG9kVWQta0D9JPjpxLk/kvyH+LGZh0KkZdTqSksjB19J8jtI/geS9zay68ha8pyd5f7dzMd2fdz+BKsjL0zusw3J2UixelJRUYE2bdidH6RXQiIi4o2KkIiIeKMiJCIi3qgIiYiINypCIiLijbrjjoelJP8Pkhcb2WCy9gWSn0hyY0Mt/ghgnWdMfXSkBdWQ3XEpJLdm5LHuuAMB75M99isCHqcxOsNMW3xgdxJ+dS05jNU1xtxM8udIzp5X7Y78LruRMYMbfkg+YQPJ1x35fTYo62viABxQd5yIiMQ4FSEREfFGRUhERLxRERIREW9UhERExBvtrHo8DCU568z53MgWBbxPsqGn27XQSP+VHMSakQbE1tyzrxvw2NY3AmjYLkC2O21jdeTdixvI4+qrruQQ7HlldcddSNYuJ3mA7lIAwO1GNsteuoFtZdyD5Gw3V2tO3DVkLeuirQ/sa3KE9EpIRES8URESERFvVIRERMQbFSEREfEm0NievLw85OXl4eOPPwYA9OjRAw8++CCGDRsGAHDOYcqUKcjPz8euXbvQv39/zJo1Cz16sHfcojXqsT1nkZw0CeAfJO9iZB3J2k/t+OM1dt4B1sZZZNMs+m+UoKNorDen2Zv7QUcFsd6avUbWlEfixL4Qe570JPlaklsjrl4la08neWeSv0Zy62HIRm2x+3ye5LtJ3gjU+9ieM844A1OnTsU777yDd955B5dffjm+//3vY926g0OMpk2bhunTp2PmzJkoKipCSkoKhgwZgqoqNldLRESaskBF6Nprr8VVV12FLl26oEuXLnj00UfRunVrrFy5Es45zJgxA5MnT8aIESPQs2dPzJ07F3v37sX8+fMb6vxFRKQRO+r3hPbv348FCxZgz549GDBgAEpKSlBWVoahQ79p3g+Hwxg4cCBWrFhBj1NdXY3KyspaHyIi0jQELkLFxcVo3bo1wuEwRo8ejYULF6J79+4oKysDACQnJ9dan5ycHLnNkpubi6SkpMhHenp60FMSEZFGKnAR6tq1K9asWYOVK1firrvuwqhRo7B+/frI7aFQ7T8Hds5FZd82ceJEVFRURD5KS0uDnpKIiDRSgcf2tGjRAp07H2wd6du3L4qKivDEE0/g/vvvBwCUlZUhNTU1sr68vDzq1dG3hcNhhMPW/IlGiPVfbCH5DSS3fnv5Nll7gR13QC75BGvHPKYDydkckZYkZ21MFtY1153kHwc4Nmu/Unfc8dbxZSPsRhazyUxTSG51sLGOtCtJnkfyS0huHZ891dhkpn4k30Zya3M89jPoGEfrNKRj/jsh5xyqq6uRkZGBlJQUFBQURG6rqalBYWEhsrKyjvVuREQkDgV6JTRp0iQMGzYM6enpqKqqwoIFC7Bs2TK8+uqrCIVCGD9+PHJycpCZmYnMzEzk5OQgISEBI0eObKjzFxGRRixQEfr0009xyy23YMeOHUhKSsI555yDV199FUOGDAEATJgwAfv27cOYMWMif6y6dOlSJCayX4OIiEhTFqgIPf3004e9PRQKITs7G9nZ2cdyTiIi0kRodpyIiHgTaHbc8dDgs+NOIznrnfhTQ51I/XDuHHLLewGOkkny5iRfT3LWwcbWH2/sOjeRPIXk/O/ejtz5JP+S5FaLVCx19bHHod1JGfrh36ND1gXG9lxkXWbWPEXWYce6Ttm4swdI/pCRsT0RWdOp1e0G8KbOlSSPIfU+O05ERKQ+qQiJiIg3KkIiIuKNipCIiHijIiQiIt4Enh3X6P2T5GzO0x1G1o6sfSz46Rw7NsdtGMlfMTLWlnMjyVm328ckt7odfXR2se0yWXdcfXTBMe824LF9sLsx57Dl7Y2MdY1ZawHeHWd1k7FOtYEk/xXJWROg9VQJOktyHcnjnF4JiYiINypCIiLijYqQiIh4oyIkIiLeqAiJiIg3Ta87jmHzmfKNbJW9tNdUOy/mu5vXg5+S/IkAx2BdcL8l+SkkZ1tjvmVkg8haNsxrL8kZqyPPGioGAC1IznZ5rQ8jSL6a5CUNdSL1gn13fvwUucFqVGTNi+y5ybrPvjKyRWTtNJKPIvmfSW59O1lXX0+S/4DkL5A8TuiVkIiIeKMiJCIi3qgIiYiINypCIiLiTXw0JoSNrDrgMUbasTWh5/NCe20xm6DToHqRnM0puSLA2kqS30Zy6x1hwG5CWEbWsg0NzyA5e/fX2hxuDVnLGioacjO+Fxvw2LHDkeeK2QvTMeDB2fPNejiz3ptnSD6W5KNJ/gsjY5v0sfFe95I8zumVkIiIeKMiJCIi3qgIiYiINypCIiLijYqQiIh4E7vdcX0RfXYrydpkI9tK1lqddABwix2bfWNZ5Bhsk60GFApdYN9wmx27OacbKWszakPyu0m+nOTWhmekHZGey+skt64H4PNVLKyNqSGxLkAfm/0duwR2A3mutDNG9HzOfhoF7Tq1nrR3kbW/DHAMACgi+ZjDnlEt3dZ0N/MN5zVkN2bs0ishERHxRkVIRES8URESERFvVIRERMQbFSEREfEm5Jxzvk/i2yorK5GUlASsQ/RmVmcGONBZJB9P8ntI/oGRdQlwHgDvnMkLeJwg2NeKdQ0a3C5yw8kBz8WwusDOew9hXWNs+Fcnki8yMmtzPQC4luSsLes1I/uMrGXYpnbWsYHG2jX3UzLDcaXRSbqhub2WTSSkTY3WZne9yVr2z/B/kJyco7lf4lqytgnNiKuoqECbNqzL9iC9EhIREW9UhERExBsVIRER8UZFSEREvFEREhERb2K3O+7vAFrXuZGNLHvDyIaStU+RPJ3kq0huOL2PnW/7gnxC2yM/dkNyu0hH2slsmNcUkrPZcdbup8bwMAC85elxkjckNhFt73E9i8ZsAcn/357orFkre+3yA+QgG0hujWazulwB3un6BcnZTqzWrLlHydomRN1xIiIS01SERETEGxUhERHxRkVIRES8id1N7bYi+n3hX5O1VkPACrL2bZK3C3DsF+yl2yrtPHSZnfvoCJnlosfFrH7uRXNt75v/lxzF2kUQ4BvPWeNvZpG1bL6KbbXVlAKg92UZRnolOcqHJGczWl4xMtY18zzJg475iW2sR8BqSQGAtsYsnq6kEeSdE+xGkL1kE8l2uCj6PLr8zVy7YbPd9ZBA9krcW27neIzk8p30SkhERLxRERIREW9UhERExBsVIRER8UZFSEREvDmm7rjc3FxMmjQJ48aNw4wZMwAAzjlMmTIF+fn52LVrF/r3749Zs2ahR48ewQ6+D0CoTraarJ1mZD8na78mOelsM8dxXEDWkm6drmQ56yhqSB3w06is6wUtyerrAh3bfXGTmYdOtnqkNpGjDCZ5dMcTAPS+7FdkvTVf5XaydhDJDz9upLaZAdYCwCkk70XyZQGObX+t+KZ+x64b2GaE9mZ8V50cnT270+6CO/NU+9/KG5qxeT5WN6b9o+7Ss+z+vTQyVmrBY8vIfcrROupXQkVFRcjPz8c555xTK582bRqmT5+OmTNnoqioCCkpKRgyZAiqqqztDkVEpCk7qiK0e/du3HTTTZg9ezbatv1mCqdzDjNmzMDkyZMxYsQI9OzZE3PnzsXevXsxf/78ejtpERGJD0dVhMaOHYurr74aV1xxRa28pKQEZWVlGDr0mxHW4XAYAwcOxIoV9l+PVldXo7KystaHiIg0DYHfE1qwYAHeffddFBUVRd1WVlYGAEhOrv0X9cnJydiyZYt5vNzcXEyZwrYGEBGReBbolVBpaSnGjRuH5557Di1bsjezgVCodkeBcy4qO2TixImoqKiIfJSWlgY5JRERacQCvRJatWoVysvL0afPNwPV9u/fj+XLl2PmzJnYuHEjgIOviFJTUyNrysvLo14dHRIOhxEOh6NvaAug7iZXbJSXdRWnkbVWtxsAsJlQpOPNRAZlbYihuvo1+kVlCV3YRnKvkdzuGgudvJmst5pSepK1rDtsHMnZN/QaI/uYrP0FyaNf7R/0qZGxxpvobsSD/p3ky0ieYmRWFxiw/GW7C+7Sq8ihYc3ZK2GLCbsLrhv5d+7LMDrbyMPwB6debubl53Yz863G12XJs38x1274wyf2nb5Mcql3gV4JDR48GMXFxVizZk3ko2/fvrjpppuwZs0anHXWWUhJSUFBQUHkc2pqalBYWIisrKx6P3kREWncAr0SSkxMRM+etf8F26pVK5xyyimRfPz48cjJyUFmZiYyMzORk5ODhIQEjBw5sv7OWkRE4kK9b+UwYcIE7Nu3D2PGjIn8serSpUuRmJhY33clIiKN3DEXoWXLltX6/1AohOzsbGRnZx/roUVEJM5pdpyIiHgTuzurNkd0Nxw7W2tX1E5kLWtiYk1WVncc69Kzx03xzjsPhl8ePcNveLcyc+3CJ9ner8a2mACANSS3hv6xHVQXkZx1mbFvxnAjs7fVLXrjYTPvd9mD5NhrjYx177EOw6Ds75HluXw7591x0Z1wn663VyZ3t/MNO+2826n2fLf7jHl9PznX/pX9FW/+2czbd7O/90sWGX8Yf4d9fuKfXgmJiIg3KkIiIuKNipCIiHijIiQiIt6oCImIiDch5xxrgfKisrISSUlJBzfGTKhzI2vKskZoLSJrWQfbpUdwcoe7P8Du0gOA00n+M5LPDnAu9eAt92Mzz8JY8hms3e9Kkv+nkXUga78kORvix44TfS4/H2cP0b2cfO+7ksdK53OtXVQXkfOw2y4r8a6Zt0GmmV/UL3on2reKrJlvQPC5b9E+LbDzdR/a+eV3BTu+NSbO6jkEgIeftfOPSEfrp2xXZTnuKioq0KbN4Xco1ishERHxRkVIRES8URESERFvVIRERMSb2B3b8yWAuu8js9E61hv/rAGhkuSs2cB6PzzIWgAgb+aimOTH2UWhp83cOTZah+0Nxd6dthoW2DGMkSsAALaTL2uGmBWVdCKPiat/0J8c42WSn2tkZEdD3GqmbfA9M3/pzRwzf6vov42UPbAeJ/lFZvpAz+hN8KaSLoFkNg6LKFpp5/0ujM5OxxXm2t83szekW6EGhLigV0IiIuKNipCIiHijIiQiIt6oCImIiDcqQiIi4k3sdsedhuixPUE2nmPNSqyhiO2NZm2CxzbGY51DH5H88NMsvAuF7jbzO3bb6/NbzSNHskbrjCBrryN5Gsl/QvLo7rvmbclSOifpMpIPj0q+KrVG+QDN08eb+V7Y+dUX/4jcp7Uh3xaydpId77E776Y+RQ5jWM42zJtq51YXHACstrrmTre74CZdZ3cv/u6Wv9sHl0ZFr4RERMQbFSEREfFGRUhERLxRERIREW9UhERExJvY3dRuGYDWdW58jXySNcuNdUItIvmvSM468ixs1BqbNbc8wLFZ4xk7dn1sjNeF5L3suJ09Jg2f/YvVZcc2oysy00r80czb4N/IcayWL7YZ3x/suHqCnYffNELWqcZ2NFxEcjYLL3r952/+2lzZ7mLSHbfD7o5bfl90dunvyWkE/mdr3RbXQwYbmd2i2rHni2a+ZV3Qc5HjTZvaiYhITFMREhERb1SERETEGxUhERHxRkVIRES8id3ZcV8D+KpOxnYuDTI77muSJ5LcmhPHOtI2kJzMz6Kz5p4PcOyeJK8P5we7z89Jk1moMHquWq9r7LX/S8a1daMns5rk1snMMVfuPWC3Xaa2qjHziq+t3V/t7j3gUpJ3M9Mn8waa+Zi7/j0qa8fmzO18xs5TB5nxpdOXRYf19M/TzxfvNfN2l/45Kvv5z+xjqAsuvumVkIiIeKMiJCIi3qgIiYiINypCIiLiTeyO7XkUQMs6N95JPsnaH4288U2nxdRtgjjEanr4V7KWbZi3jeTfI7k1dYW9/96P5I+S3DKU5NH7wh3ExhOxNhdrGgtrHAnaUELu80DqyKgsRL/gV5O8HcmteUt2t0oRrjfzfighx64Pp5hpJT4z8zawOgLskUDAtSRfS/KXzdQhelbQCaFXyDGksdLYHhERiWkqQiIi4o2KkIiIeKMiJCIi3qgIiYiIN7E7tqct+Hicum4xMrZ/GdukbgnJrcYptn8ZG/3TkeSsa866bjayKMime0Gx82NNY2wMkdXxxo5hjUkC+PfzUzv+0Q/mR2V//GF0BgB4gRw7gGe+tDvS/i28k3xGKNDxf2fso3fLxWy13b7YBq+T9ZVRSYicXvJp0eN2AKAv6Zhc+trZZv7VfnIq0uTolZCIiHijIiQiIt6oCImIiDcqQiIi4o2KkIiIeBNodlx2djamTJlSK0tOTkZZWRkAwDmHKVOmID8/H7t27UL//v0xa9Ys9OjR44hPKDI7bh6AhDo3nn7EhwEWkbwzyReSfKKRRTcTHcRmrTGLSG7NiXuVrO1I8qUBziOb5Kzzjs3ZY+didc2xtW1J/qUdn97dzrdZs/N+SY4tIg2iQWbH9ejRAzt27Ih8FBcXR26bNm0apk+fjpkzZ6KoqAgpKSkYMmQIqqpY362IiDRlgf9OqFmzZkhJSYnKnXOYMWMGJk+ejBEjDo61njt3LpKTkzF//nzceac9Aru6uhrV1dWR/6+sZC8zREQk3gR+JbRp0yakpaUhIyMDN9xwAzZv3gwAKCkpQVlZGYYO/WZfgHA4jIEDB2LFihX0eLm5uUhKSop8pKenH8VliIhIYxSoCPXv3x/z5s3DkiVLMHv2bJSVlSErKwufffZZ5H2h5OTkWp/z7feMLBMnTkRFRUXko7S09CguQ0REGqNAv44bNmxY5L979eqFAQMGoFOnTpg7dy4uvPBCAECozrwP51xU9m3hcBjhcDjIaYiISJw4ptlxrVq1Qq9evbBp0yYMHz4cAFBWVobU1NTImvLy8qhXR0ekOaJ35Cwia62ZbezK2FtOg0meFuAYJ5N8D8lnkdw6dzavjnSNUalGxrrd2Ow+tvspm51nzb1jc+kYcuxtH5D1zwQ8voh4cUx/J1RdXY33338fqampyMjIQEpKCgoKCiK319TUoLCwEFlZQXuXRUSkKQj0SugXv/gFrr32Wpx55pkoLy/HI488gsrKSowaNQqhUAjjx49HTk4OMjMzkZmZiZycHCQkJGDkyJENdf4iItKIBSpCn3zyCW688Ubs3LkTp512Gi688EKsXLkSHTp0AABMmDAB+/btw5gxYyJ/rLp06VIkJrLf04iISFMWqAgtWLDgsLeHQiFkZ2cjOzv7WM5JRESaCM2OExERb2J3Z9VdOPLOr6+N7AKyls2IY+uXGxmbP8ewzrZ3Ah7HsjXgemtH0/8ja1nH4MAAxwbs3U/ZJCc2r451JP6B5JtJLkeEjZQ83J9biBwNvRISERFvVIRERMQbFSEREfFGRUhERLyJ3caEKkQ3HLBxMdYb4h3I2u0kf43kG4zst2Qt82HA9ccbm6rUi+RsnA+7TqupoGPAY39M8jySyzFRA4IcL3olJCIi3qgIiYiINypCIiLijYqQiIh4oyIkIiLexG53XDNEn10xWdvRyNimaWwUDRvns87IPraXNr/Yzr8qJ8duSNbmdYDdfXYlWcu64xj2Nbe6FzuRtWzjwocCnouINAp6JSQiIt6oCImIiDcqQiIi4o2KkIiIeKMiJCIi3sRud9xJiO7kWkTWWnPi2KZpz5J8NclXGpk1Tw6H2dONbcjWkFjHm7XB3j6yNpHkp5OczfZLJ7klSJei1IvO954TlX34m/c8nIk0RXolJCIi3qgIiYiINypCIiLijYqQiIh4oyIkIiLehJxzzvdJfFtlZSWSkpKAXwAI17mR7QB6r5H9jawdRXI2U87aubOLvfT0jXa+7QFybNaRt5TkQfwXyTsbWW+ylvVOsrl0zHoj6x7wGNroU6TRqaioQJs2bQ67Rq+ERETEGxUhERHxRkVIRES8URESERFvVIRERMSb2J0dl4ro2XETAnz+gID39xbJXzKyD+ylX7NjP0Pynoc9oyNzJsmbk9zqhAsy2w2wu90Avltq0E44Qy/Sw1msrjmRRk2vhERExBsVIRER8UZFSEREvFEREhERb2K3MeFBRI9qYW98W/4R8P6i9/UCAIQ2RWeutb2W9Qh8+k9yQxbJ3yC55X9Ibm30B9gjd0rJWtawUA+NBkG1Pf53KSLHgV4JiYiINypCIiLijYqQiIh4oyIkIiLeqAiJiIg3sdsd9y6AxDrZBrL2ciM7kazdT/Iddnxbq+hsDjlE3dP9Tu0CrL2K5Gw8T5Bjsy64PSQ3vib1hTUMprFPmE3yO479XESk4emVkIiIeKMiJCIi3qgIiYiINypCIiLiTeAitG3bNtx888045ZRTkJCQgPPOOw+rVq2K3O6cQ3Z2NtLS0nDSSSdh0KBBWLduXb2etIiIxIdA3XG7du3CRRddhMsuuwyvvPIK2rdvj48++ggnn3xyZM20adMwffp0PPvss+jSpQseeeQRDBkyBBs3bkRiYoD+sbcAJNTJ6m5yd8iXRsY6vj4nOemam2NsmjaZbLAWuNTuI/mFRjaerGVtY6xrrtrIwmQt64LbSfJTSW4h3Ygrquz8X7qcb+bzfrLYzFvccUaAkxERXwIVocceewzp6emYM+ebJuWOHTtG/ts5hxkzZmDy5MkYMWIEAGDu3LlITk7G/Pnzceedd9bPWYuISFwI9Ou4xYsXo2/fvrjuuuvQvn179O7dG7Nnf/OHGiUlJSgrK8PQoUMjWTgcxsCBA7FixQrzmNXV1aisrKz1ISIiTUOgIrR582bk5eUhMzMTS5YswejRo3Hvvfdi3rx5AICysjIAQHJycq3PS05OjtxWV25uLpKSkiIf6ens92giIhJvAhWhAwcO4Pzzz0dOTg569+6NO++8E3fccQfy8vJqrQuFar+R4pyLyg6ZOHEiKioqIh+lpWxzGxERiTeBilBqaiq6d6+9o9nZZ5+NrVu3AgBSUlIAIOpVT3l5edSro0PC4TDatGlT60NERJqGQI0JF110ETZu3Fgr++CDD9Chw8FtPDMyMpCSkoKCggL07t0bAFBTU4PCwkI89thjwc7sSePsVpK11pwwtrPoFJI/Q/J3oqNHu5K1OSQ/jeSrSf6wkbHvlLVT6uFYnXBWx9zhBOmCY8h5tyH5Urxr5x9cXw8nIyK+BCpCP/vZz5CVlYWcnBz86Ec/wttvv438/Hzk5+cDOPhruPHjxyMnJweZmZnIzMxETk4OEhISMHLkyAa5ABERabwCFaF+/fph4cKFmDhxIh5++GFkZGRgxowZuOmmmyJrJkyYgH379mHMmDHYtWsX+vfvj6VLlwb7GyEREWkSAm/lcM011+Caa66ht4dCIWRnZyM7O/tYzktERJoAzY4TERFvYndTu0cQPTamG1mbGx11K7KXfrTKzi+/lRzbGK2zgWyut4U1Gtxux81vtPOvFhlhP3Js1lRAxt+YTQVsbA/Bvg1sz0FrzM+lpLmhEznEC+vtvLLHW+xeRaQR0CshERHxRkVIRES8URESERFvVIRERMQbFSEREfEm5JwjW7T5UVlZiaSkJOBHAFrUufEC8kn3Hvnx73dXmPmzb/7FzC8xutL+2Mc+9idrTzHzNfjMzK+GfZ+hadHn2HuCfZ+rD9h5ffzzInAXHGFNVZptZAAAe86tiDRCFRUV3zkPVK+ERETEGxUhERHxRkVIRES8URESERFvYm5sT6RP4ivjRmOETlDVlV+b+YE99vqvKo1wv722qtLuEthLzqUS5E6/NO7SOg8AaMDGBHKZgdXU03FEpHE5kr63mOuO++STT5Cenu77NERE5BiVlpbijDPOOOyamCtCBw4cwPbt25GYmIiqqiqkp6ejtLQ0rrf9rqys1HXGkaZwnU3hGgFd59FyzqGqqgppaWk44YTD/1om5n4dd8IJJ0QqZyh08I9G2rRpE9cPgEN0nfGlKVxnU7hGQNd5NJKSko5onRoTRETEGxUhERHxJqaLUDgcxkMPPYRwOOCua42MrjO+NIXrbArXCOg6j4eYa0wQEZGmI6ZfCYmISHxTERIREW9UhERExBsVIRER8UZFSEREvInpIvTkk08iIyMDLVu2RJ8+ffDXv/7V9ykdk+XLl+Paa69FWloaQqEQFi1aVOt25xyys7ORlpaGk046CYMGDcK6dev8nOxRys3NRb9+/ZCYmIj27dtj+PDh2LhxY6018XCdeXl5OOeccyJ/YT5gwAC88sorkdvj4Rrrys3NRSgUwvjx4yNZPFxndnY2QqFQrY+UlJTI7fFwjYds27YNN998M0455RQkJCTgvPPOw6pVqyK3e7lWF6MWLFjgmjdv7mbPnu3Wr1/vxo0b51q1auW2bNni+9SO2ssvv+wmT57sXnjhBQfALVy4sNbtU6dOdYmJie6FF15wxcXF7vrrr3epqamusrLSzwkfhSuvvNLNmTPHrV271q1Zs8ZdffXV7swzz3S7d++OrImH61y8eLF76aWX3MaNG93GjRvdpEmTXPPmzd3atWudc/Fxjd/29ttvu44dO7pzzjnHjRs3LpLHw3U+9NBDrkePHm7Hjh2Rj/Ly8sjt8XCNzjn3+eefuw4dOrjbbrvN/f3vf3clJSXuL3/5i/vwww8ja3xca8wWoQsuuMCNHj26VtatWzf3wAMPeDqj+lW3CB04cMClpKS4qVOnRrIvv/zSJSUlud/+9rcezrB+lJeXOwCusLDQORe/1+mcc23btnVPPfVU3F1jVVWVy8zMdAUFBW7gwIGRIhQv1/nQQw+5c88917wtXq7ROefuv/9+d/HFF9PbfV1rTP46rqamBqtWrcLQoUNr5UOHDsWKFSs8nVXDKikpQVlZWa1rDofDGDhwYKO+5oqKCgBAu3btAMTnde7fvx8LFizAnj17MGDAgLi7xrFjx+Lqq6/GFVdcUSuPp+vctGkT0tLSkJGRgRtuuAGbN28GEF/XuHjxYvTt2xfXXXcd2rdvj969e2P27NmR231da0wWoZ07d2L//v1ITk6ulScnJ6OsrMzTWTWsQ9cVT9fsnMN9992Hiy++GD179gQQX9dZXFyM1q1bIxwOY/To0Vi4cCG6d+8eV9e4YMECvPvuu8jNzY26LV6us3///pg3bx6WLFmC2bNno6ysDFlZWfjss8/i5hoBYPPmzcjLy0NmZiaWLFmC0aNH495778W8efMA+Pt+xtxWDt92aCuHQ5xzUVm8iadrvvvuu/Hee+/hzTffjLotHq6za9euWLNmDb744gu88MILGDVqFAoLCyO3N/ZrLC0txbhx47B06VK0bNmSrmvs1zls2LDIf/fq1QsDBgxAp06dMHfuXFx44YUAGv81Agf3auvbty9ycnIAAL1798a6deuQl5eHW2+9NbLueF9rTL4SOvXUU3HiiSdGVd/y8vKoKh0vDnXjxMs133PPPVi8eDHeeOONWjsrxtN1tmjRAp07d0bfvn2Rm5uLc889F0888UTcXOOqVatQXl6OPn36oFmzZmjWrBkKCwvxm9/8Bs2aNYtcS2O/zrpatWqFXr16YdOmTXHzvQSA1NRUdO/evVZ29tlnY+vWrQD8PTdjsgi1aNECffr0QUFBQa28oKAAWVlZns6qYWVkZCAlJaXWNdfU1KCwsLBRXbNzDnfffTdefPFFvP7668jIyKh1e7xcp8U5h+rq6ri5xsGDB6O4uBhr1qyJfPTt2xc33XQT1qxZg7POOisurrOu6upqvP/++0hNTY2b7yUAXHTRRVF/LvHBBx+gQ4cOADw+Nxus5eEYHWrRfvrpp9369evd+PHjXatWrdzHH3/s+9SOWlVVlVu9erVbvXq1A+CmT5/uVq9eHWk7nzp1qktKSnIvvviiKy4udjfeeGOjawW96667XFJSklu2bFmtlte9e/dG1sTDdU6cONEtX77clZSUuPfee89NmjTJnXDCCW7p0qXOufi4Rsu3u+Oci4/r/PnPf+6WLVvmNm/e7FauXOmuueYal5iYGPlZEw/X6NzBNvtmzZq5Rx991G3atMn9/ve/dwkJCe65556LrPFxrTFbhJxzbtasWa5Dhw6uRYsW7vzzz4+0+TZWb7zxhgMQ9TFq1Cjn3MEWyYceesilpKS4cDjsLr30UldcXOz3pAOyrg+AmzNnTmRNPFzn7bffHnlsnnbaaW7w4MGRAuRcfFyjpW4RiofrPPS3MM2bN3dpaWluxIgRbt26dZHb4+EaD/nzn//sevbs6cLhsOvWrZvLz8+vdbuPa9V+QiIi4k1MvickIiJNg4qQiIh4oyIkIiLeqAiJiIg3KkIiIuKNipCIiHijIiQiIt6oCImIiDcqQiIi4o2KkIiIeKMiJCIi3vx/44kcNyFAaOsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in val_dataloader:\n",
    "    images, class_nums = batch\n",
    "    plt.imshow(images[4].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    plt.imshow(images[19].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCwKB-3nKm1-"
   },
   "source": [
    "\n",
    "## Assignment 1. \n",
    "\n",
    "5 points\n",
    "Achieve at least 0.44 on validation. In this task it is forbidden to use pre-trained models and image resizing.\n",
    "\n",
    "\n",
    "In order to beat the scor (considered below) by 2.5/5 points (i.e. half for the task) it is enough to follow a couple of simple rules of life:\n",
    "1. augmentation (without it it will be very difficult)\n",
    "2. Optimizers can (and should) be used with each other. However, when you test something, don't change several parameters at once - you will throw off the logic of the experiments\n",
    "3. do not use full-link models or the very first convolutional models, use more modern architectures (that you met in the lectures).\n",
    "4. Look at all the notebooks from past seminars and make something common out of them. Seminar notebooks will suffice over and above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWR2l6ymZfRJ"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is kinda a resnet but adjusted to 64x63 pictures by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigFloppaNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BigFloppaNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64,kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=True )\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.drop_fc = nn.Dropout(0.5)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        self.layer1 =self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer( 256, 2, stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2, stride = 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear = nn.Linear(4096, 200)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2, stride = 2)\n",
    "\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, images, target=None):\n",
    "        out = self.conv1(images)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.drop_fc(out)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def get_accuracy(self, dataloader):\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in  dataloader:\n",
    "                outputs = self.forward(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigFloppaModule(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.RMSprop(self.model.parameters(), lr = self.learning_rate, weight_decay=1e-4)\n",
    "        lambda_func = lambda epoch: 0.96**epoch\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_func)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        output = self.model(x)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        acc = (torch.argmax(output, dim=1) == y).float().mean()\n",
    "        self.log('train_acc', acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('val_loss', val_loss, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        acc = (torch.argmax(y_hat, dim=1) == y).float().mean()\n",
    "        self.log('val_acc', acc, prog_bar=True, on_epoch=True)\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wdtrzlyh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▅▅▇▇▇▇▇▇███████</td></tr><tr><td>train_acc_epoch</td><td>▁▃▅▆▇█</td></tr><tr><td>train_acc_step</td><td>▁▁▁▂▂▁▄▁▃▄▄▄▄▃▄▄▅▅▄▄▄▅▄▇▇▇▅▅▄▄█▄▅▇█▇▆▇▇▅</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▂▂▁</td></tr><tr><td>train_loss_step</td><td>██▇▆▆▆▅▆▅▄▄▄▅▄▄▄▄▃▃▃▄▃▄▂▂▂▂▃▂▂▁▃▃▁▂▃▁▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▄▆▇██</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>train_acc_epoch</td><td>0.28887</td></tr><tr><td>train_acc_step</td><td>0.22</td></tr><tr><td>train_loss_epoch</td><td>3.04679</td></tr><tr><td>train_loss_step</td><td>2.94679</td></tr><tr><td>trainer/global_step</td><td>11999</td></tr><tr><td>val_acc</td><td>0.2592</td></tr><tr><td>val_loss</td><td>3.19503</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-violet-2</strong> at: <a href='https://wandb.ai/to505to505_team/FloppaNet1/runs/wdtrzlyh' target=\"_blank\">https://wandb.ai/to505to505_team/FloppaNet1/runs/wdtrzlyh</a><br/> View project at: <a href='https://wandb.ai/to505to505_team/FloppaNet1' target=\"_blank\">https://wandb.ai/to505to505_team/FloppaNet1</a><br/>Synced 6 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240516_000849-wdtrzlyh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wdtrzlyh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dmitrii_sakharov/Docs/Study.obs/Study/ИАД ГЛУБИННОЕ/hw/hw2/wandb/run-20240516_210954-3fyidxhu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/to505to505_team/FloppaNet1/runs/3fyidxhu' target=\"_blank\">stellar-donkey-16</a></strong> to <a href='https://wandb.ai/to505to505_team/FloppaNet1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/to505to505_team/FloppaNet1' target=\"_blank\">https://wandb.ai/to505to505_team/FloppaNet1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/to505to505_team/FloppaNet1/runs/3fyidxhu' target=\"_blank\">https://wandb.ai/to505to505_team/FloppaNet1/runs/3fyidxhu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project= 'FloppaNet1')\n",
    "wandb_logger = WandbLogger(log_model='all', project='FloppaNet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',  \n",
    "    dirpath='checkpoints',  \n",
    "    filename='FloppaNet1-{epoch:02d}-{val_acc:.2f}',  \n",
    "    save_top_k=1,  \n",
    "    mode='max'  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model (it was trained with the same code but on google collab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = run.use_artifact('to505to505_team/uncategorized/model-9vysdrn4:v8', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "model_path = f'{artifact_dir}/model.ckpt'\n",
    "module = BigFloppaModule.load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BigFloppaModule(\n",
       "  (model): BigFloppaNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "    (drop_fc): Dropout(p=0.5, inplace=False)\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear): Linear(in_features=4096, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | BigFloppaNet | 3.6 M \n",
      "---------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.391    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30327fd06c641fc806d63eea65f2bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2ac401f1a84880adf36b9f09ea3229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942c068ca9194f58b421ed5e0204901d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e97a0b85a24550a094afb2b2f1813b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b4550f47fe4f07b0e787f3d2f96abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0287f23ce34edcb575d79d91600b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26d7efad22544b3b2b347385b15fd57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7820f281be93486ca73a5908e4c35e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a488d17f1a7c4d888e355b83b1cc2911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ff6fac71e5400383e54bf9fb62b097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962462ccac3d4737ad414b22696f8443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe49824bac8b46399353edf1bf77232a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57f5b16b3d048a58e907d7e1b8b1772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569c06a29bed47de8a88b1507f3ffbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a657590b03f4470b653fe07defa62ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ceee470fcb44a5a77bdfbcd1bc1f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e9b680d7294a61a4ae283bdc0d6ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671d5e386ee945488d40e1652c4f679b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5447271c324af3954bd80cea828c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5a6d04120f45bfa72632e98f870c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf92def809145d59ff64680ea58ace4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a715189dd9441baa76faab6d171b444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "module.learning_rate = 0.0063\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", max_epochs=20, logger=wandb_logger, callbacks=[checkpoint_callback] )\n",
    "trainer.fit(module, train_dataloaders=train_dataloader,val_dataloaders= val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to wandb_run: https://api.wandb.ai/links/to505to505_team/4pop8p3b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eoTAB1fSOuk"
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4M_BAiMNl1rL"
   },
   "outputs": [],
   "source": [
    "def evaluate_task(model, test_dataloader, device=\"cuda:0\"):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    for images, labels in tqdm(test_dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            acc_batch = (torch.argmax(model(images), dim=1) == labels).float().mean()\n",
    "        accuracy += acc_batch\n",
    "    accuracy = accuracy / len(test_dataloader)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4436998963356018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BigFloppaModule.load_from_checkpoint(model_path)\n",
    "\n",
    "accuracy = evaluate_task(model, val_dataloader)\n",
    "print(f\"Accuracy:  {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZqSdlQQKukS"
   },
   "source": [
    "## Task 2\n",
    "\n",
    "5 points\n",
    "Achieve an accuracy on validation of at least 0.83. In this task, it is possible to resize and use pretrain.\n",
    "\n",
    "In order to get 2.5/5 points (i.e. half for the task) you just need to follow a couple of simple life rules:\n",
    "1. augmentation (without it it will be very difficult)\n",
    "2. Optimizers can (and should) be used with each other. However, when you test something, don't change several parameters at once - you will throw off the logic of the experiments\n",
    "3. do not use full-link models or the very first convolutional models, use more modern architectures (that you met in lectures or you can go further).\n",
    "4. Try to see the quality of the original model without pre-training first, save it as a baseline. From here you will realize which layers need to be pre-trained.\n",
    "5. Look at all the notebooks from past seminars and make something common out of them. Seminar notebooks will suffice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose([\n",
    "     v2.RandomResizedCrop(\n",
    "         size=(224, 224),\n",
    "        scale=(0.7, 1.0),\n",
    "        ratio=(0.8, 1.31),\n",
    "        antialias=True\n",
    "    ),\n",
    "    v2.ColorJitter(hue=0.05, saturation=0.05),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(),\n",
    "    v2.RandomRotation(20),\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True ),\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_val = v2.Compose([\n",
    "    v2.Resize(224, antialias=True),\n",
    "     v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True ),\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU CAN DEFINE AUGMENTATIONS HERE\n",
    "train_transform = transforms\n",
    "val_transform = transforms_val\n",
    "\n",
    "train_dataset = ImageFolder('dataset/dataset/train', transform=train_transform)\n",
    "val_dataset = ImageFolder('dataset/dataset/val', transform=val_transform)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True,num_workers=2, persistent_workers=True )\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDzXM5rNxNQp"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification, AdamW\n",
    "from transformers import ViTModel, ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedFloppaModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "      super(EmbedFloppaModel, self).__init__()\n",
    "      # self.flatten = nn.Flatten()\n",
    "      self.model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k',\n",
    "                                                              num_labels=200                                                      )\n",
    "\n",
    "      for param in self.model.parameters():\n",
    "          param.requires_grad = False\n",
    "      for param in self.model.classifier.parameters():\n",
    "          param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, images):\n",
    "      out = self.model(images)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am using vit to get a CLS token and pul a linear layer after it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedFloppaModule(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr = self.learning_rate, weight_decay=1e-4)\n",
    "        lambda_func = lambda epoch: 0.975**epoch\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_func)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        output = self.model(x)\n",
    "        logits = output.logits\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        acc = (torch.argmax(logits, dim=1) == y).float().mean()\n",
    "        self.log('train_acc', acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y_hat = self.model(x)\n",
    "        logits = y_hat.logits\n",
    "\n",
    "        val_loss = F.cross_entropy(logits, y)\n",
    "        self.log('val_loss', val_loss, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        acc = (torch.argmax(logits, dim=1) == y).float().mean()\n",
    "        self.log('val_acc', acc, prog_bar=True, on_epoch=True)\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "run = wandb.init()\n",
    "wandb_logger = WandbLogger(log_model='all', project='Pretrain' )\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',  \n",
    "    dirpath='checkpoints', \n",
    "    filename='PretrainEff1-{epoch:02d}-{val_acc:.2f}',  \n",
    "    save_top_k=1,  \n",
    "    mode='max'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = run.use_artifact('to505to505_team/uncategorized/model-39hpepx4:v2', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "model_path = f'{artifact_dir}/model.ckpt'\n",
    "module = EmbedFloppaModule.load_from_checkpoint(model_path)\n",
    "module.learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | EmbedFloppaModel | 86.0 M\n",
      "-------------------------------------------\n",
      "153 K     Trainable params\n",
      "85.8 M    Non-trainable params\n",
      "86.0 M    Total params\n",
      "343.810   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d479530b4144ca9d93b44386e01e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e912116b4842e9a722653c9bb626b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3dc77d23304b5594d6714cdaf70e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b03b3d4efc4638b5b2577909d54984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c9425b078c4b2882b90d4339db9c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a24d0d79154fb1bc94dbf49ba7097b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06eaa6550fd4e1e9363310648f34035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812338d51f954b53a1089d58c922050d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81641b8069504c408419058d960679e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fff4b88fea4ac18ce3e9b17916c13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7209fd2fa13947f6b87d3f8d38f17c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", max_epochs=10, logger=wandb_logger, callbacks=[checkpoint_callback] )\n",
    "trainer.fit(module, train_dataloaders=train_dataloader,val_dataloaders= val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5D2bwOKSHVp"
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_task(model, test_dataloader, device=\"cuda:0\"):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    for images, labels in tqdm(test_dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            acc_batch = (torch.argmax(model(images).logits, dim=1) == labels).float().mean()\n",
    "        accuracy += acc_batch\n",
    "    accuracy = accuracy / len(test_dataloader)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/625 [00:00<01:14,  8.38it/s]\u001b[A\n",
      "  0%|          | 2/625 [00:00<01:47,  5.77it/s]\u001b[A\n",
      "  0%|          | 3/625 [00:00<01:51,  5.59it/s]\u001b[A\n",
      "  1%|          | 4/625 [00:00<01:58,  5.25it/s]\u001b[A\n",
      "  1%|          | 5/625 [00:00<01:54,  5.40it/s]\u001b[A\n",
      "  1%|          | 6/625 [00:01<01:59,  5.20it/s]\u001b[A\n",
      "  1%|          | 7/625 [00:01<01:57,  5.26it/s]\u001b[A\n",
      "  1%|▏         | 8/625 [00:01<01:56,  5.29it/s]\u001b[A\n",
      "  1%|▏         | 9/625 [00:01<01:58,  5.18it/s]\u001b[A\n",
      "  2%|▏         | 10/625 [00:01<01:56,  5.26it/s]\u001b[A\n",
      "  2%|▏         | 11/625 [00:02<01:54,  5.35it/s]\u001b[A\n",
      "  2%|▏         | 12/625 [00:02<02:04,  4.93it/s]\u001b[A\n",
      "  2%|▏         | 13/625 [00:02<02:03,  4.95it/s]\u001b[A\n",
      "  2%|▏         | 14/625 [00:02<02:02,  4.99it/s]\u001b[A\n",
      "  2%|▏         | 15/625 [00:02<01:55,  5.29it/s]\u001b[A\n",
      "  3%|▎         | 16/625 [00:03<01:52,  5.40it/s]\u001b[A\n",
      "  3%|▎         | 17/625 [00:03<01:55,  5.26it/s]\u001b[A\n",
      "  3%|▎         | 18/625 [00:03<01:56,  5.20it/s]\u001b[A\n",
      "  3%|▎         | 19/625 [00:03<01:57,  5.17it/s]\u001b[A\n",
      "  3%|▎         | 20/625 [00:03<01:57,  5.14it/s]\u001b[A\n",
      "  3%|▎         | 21/625 [00:04<01:56,  5.19it/s]\u001b[A\n",
      "  4%|▎         | 22/625 [00:04<01:57,  5.13it/s]\u001b[A\n",
      "  4%|▎         | 23/625 [00:04<01:58,  5.09it/s]\u001b[A\n",
      "  4%|▍         | 24/625 [00:04<01:58,  5.05it/s]\u001b[A\n",
      "  4%|▍         | 25/625 [00:04<01:58,  5.06it/s]\u001b[A\n",
      "  4%|▍         | 26/625 [00:04<01:57,  5.09it/s]\u001b[A\n",
      "  4%|▍         | 27/625 [00:05<01:57,  5.08it/s]\u001b[A\n",
      "  4%|▍         | 28/625 [00:05<01:58,  5.04it/s]\u001b[A\n",
      "  5%|▍         | 29/625 [00:05<01:58,  5.01it/s]\u001b[A\n",
      "  5%|▍         | 30/625 [00:05<01:59,  5.00it/s]\u001b[A\n",
      "  5%|▍         | 31/625 [00:05<01:57,  5.05it/s]\u001b[A\n",
      "  5%|▌         | 32/625 [00:06<01:57,  5.04it/s]\u001b[A\n",
      "  5%|▌         | 33/625 [00:06<01:57,  5.05it/s]\u001b[A\n",
      "  5%|▌         | 34/625 [00:06<01:57,  5.05it/s]\u001b[A\n",
      "  6%|▌         | 35/625 [00:06<01:57,  5.01it/s]\u001b[A\n",
      "  6%|▌         | 36/625 [00:06<01:56,  5.04it/s]\u001b[A\n",
      "  6%|▌         | 37/625 [00:07<01:57,  5.01it/s]\u001b[A\n",
      "  6%|▌         | 38/625 [00:07<01:57,  4.98it/s]\u001b[A\n",
      "  6%|▌         | 39/625 [00:07<01:57,  4.98it/s]\u001b[A\n",
      "  6%|▋         | 40/625 [00:07<01:57,  4.97it/s]\u001b[A\n",
      "  7%|▋         | 41/625 [00:07<01:57,  4.97it/s]\u001b[A\n",
      "  7%|▋         | 42/625 [00:08<01:57,  4.97it/s]\u001b[A\n",
      "  7%|▋         | 43/625 [00:08<01:57,  4.95it/s]\u001b[A\n",
      "  7%|▋         | 44/625 [00:08<01:57,  4.93it/s]\u001b[A\n",
      "  7%|▋         | 45/625 [00:08<01:57,  4.94it/s]\u001b[A\n",
      "  7%|▋         | 46/625 [00:09<01:57,  4.94it/s]\u001b[A\n",
      "  8%|▊         | 47/625 [00:09<01:56,  4.96it/s]\u001b[A\n",
      "  8%|▊         | 48/625 [00:09<01:56,  4.94it/s]\u001b[A\n",
      "  8%|▊         | 49/625 [00:09<01:57,  4.92it/s]\u001b[A\n",
      "  8%|▊         | 50/625 [00:09<01:58,  4.85it/s]\u001b[A\n",
      "  8%|▊         | 51/625 [00:10<01:57,  4.90it/s]\u001b[A\n",
      "  8%|▊         | 52/625 [00:10<01:55,  4.97it/s]\u001b[A\n",
      "  8%|▊         | 53/625 [00:10<01:55,  4.96it/s]\u001b[A\n",
      "  9%|▊         | 54/625 [00:10<01:55,  4.93it/s]\u001b[A\n",
      "  9%|▉         | 55/625 [00:10<01:55,  4.95it/s]\u001b[A\n",
      "  9%|▉         | 56/625 [00:11<01:55,  4.93it/s]\u001b[A\n",
      "  9%|▉         | 57/625 [00:11<01:54,  4.95it/s]\u001b[A\n",
      "  9%|▉         | 58/625 [00:11<01:55,  4.91it/s]\u001b[A\n",
      "  9%|▉         | 59/625 [00:11<01:55,  4.90it/s]\u001b[A\n",
      " 10%|▉         | 60/625 [00:11<01:54,  4.92it/s]\u001b[A\n",
      " 10%|▉         | 61/625 [00:12<01:54,  4.93it/s]\u001b[A\n",
      " 10%|▉         | 62/625 [00:12<01:53,  4.97it/s]\u001b[A\n",
      " 10%|█         | 63/625 [00:12<01:53,  4.96it/s]\u001b[A\n",
      " 10%|█         | 64/625 [00:12<01:53,  4.93it/s]\u001b[A\n",
      " 10%|█         | 65/625 [00:12<01:53,  4.94it/s]\u001b[A\n",
      " 11%|█         | 66/625 [00:13<01:53,  4.91it/s]\u001b[A\n",
      " 11%|█         | 67/625 [00:13<01:53,  4.94it/s]\u001b[A\n",
      " 11%|█         | 68/625 [00:13<01:52,  4.94it/s]\u001b[A\n",
      " 11%|█         | 69/625 [00:13<01:52,  4.93it/s]\u001b[A\n",
      " 11%|█         | 70/625 [00:13<01:53,  4.91it/s]\u001b[A\n",
      " 11%|█▏        | 71/625 [00:14<01:53,  4.87it/s]\u001b[A\n",
      " 12%|█▏        | 72/625 [00:14<01:54,  4.83it/s]\u001b[A\n",
      " 12%|█▏        | 73/625 [00:14<01:53,  4.87it/s]\u001b[A\n",
      " 12%|█▏        | 74/625 [00:14<01:53,  4.86it/s]\u001b[A\n",
      " 12%|█▏        | 75/625 [00:14<01:51,  4.93it/s]\u001b[A\n",
      " 12%|█▏        | 76/625 [00:15<01:52,  4.88it/s]\u001b[A\n",
      " 12%|█▏        | 77/625 [00:15<01:52,  4.88it/s]\u001b[A\n",
      " 12%|█▏        | 78/625 [00:15<01:52,  4.85it/s]\u001b[A\n",
      " 13%|█▎        | 79/625 [00:15<01:52,  4.87it/s]\u001b[A\n",
      " 13%|█▎        | 80/625 [00:15<01:51,  4.87it/s]\u001b[A\n",
      " 13%|█▎        | 81/625 [00:16<01:53,  4.81it/s]\u001b[A\n",
      " 13%|█▎        | 82/625 [00:16<01:52,  4.83it/s]\u001b[A\n",
      " 13%|█▎        | 83/625 [00:16<01:51,  4.85it/s]\u001b[A\n",
      " 13%|█▎        | 84/625 [00:16<01:51,  4.83it/s]\u001b[A\n",
      " 14%|█▎        | 85/625 [00:16<01:51,  4.82it/s]\u001b[A\n",
      " 14%|█▍        | 86/625 [00:17<01:51,  4.82it/s]\u001b[A\n",
      " 14%|█▍        | 87/625 [00:17<01:51,  4.81it/s]\u001b[A\n",
      " 14%|█▍        | 88/625 [00:17<01:52,  4.78it/s]\u001b[A\n",
      " 14%|█▍        | 89/625 [00:17<01:52,  4.78it/s]\u001b[A\n",
      " 14%|█▍        | 90/625 [00:18<01:51,  4.81it/s]\u001b[A\n",
      " 15%|█▍        | 91/625 [00:18<01:52,  4.75it/s]\u001b[A\n",
      " 15%|█▍        | 92/625 [00:18<01:51,  4.79it/s]\u001b[A\n",
      " 15%|█▍        | 93/625 [00:18<01:51,  4.79it/s]\u001b[A\n",
      " 15%|█▌        | 94/625 [00:18<01:51,  4.77it/s]\u001b[A\n",
      " 15%|█▌        | 95/625 [00:19<01:50,  4.79it/s]\u001b[A\n",
      " 15%|█▌        | 96/625 [00:19<01:50,  4.77it/s]\u001b[A\n",
      " 16%|█▌        | 97/625 [00:19<01:50,  4.77it/s]\u001b[A\n",
      " 16%|█▌        | 98/625 [00:19<01:50,  4.77it/s]\u001b[A\n",
      " 16%|█▌        | 99/625 [00:19<01:50,  4.76it/s]\u001b[A\n",
      " 16%|█▌        | 100/625 [00:20<01:50,  4.75it/s]\u001b[A\n",
      " 16%|█▌        | 101/625 [00:20<01:50,  4.76it/s]\u001b[A\n",
      " 16%|█▋        | 102/625 [00:20<01:50,  4.75it/s]\u001b[A\n",
      " 16%|█▋        | 103/625 [00:20<01:49,  4.76it/s]\u001b[A\n",
      " 17%|█▋        | 104/625 [00:20<01:50,  4.73it/s]\u001b[A\n",
      " 17%|█▋        | 105/625 [00:21<01:49,  4.76it/s]\u001b[A\n",
      " 17%|█▋        | 106/625 [00:21<01:49,  4.74it/s]\u001b[A\n",
      " 17%|█▋        | 107/625 [00:21<01:49,  4.74it/s]\u001b[A\n",
      " 17%|█▋        | 108/625 [00:21<01:49,  4.72it/s]\u001b[A\n",
      " 17%|█▋        | 109/625 [00:22<01:49,  4.73it/s]\u001b[A\n",
      " 18%|█▊        | 110/625 [00:22<01:49,  4.71it/s]\u001b[A\n",
      " 18%|█▊        | 111/625 [00:22<01:49,  4.71it/s]\u001b[A\n",
      " 18%|█▊        | 112/625 [00:22<01:48,  4.72it/s]\u001b[A\n",
      " 18%|█▊        | 113/625 [00:22<01:48,  4.73it/s]\u001b[A\n",
      " 18%|█▊        | 114/625 [00:23<01:48,  4.72it/s]\u001b[A\n",
      " 18%|█▊        | 115/625 [00:23<01:48,  4.72it/s]\u001b[A\n",
      " 19%|█▊        | 116/625 [00:23<01:48,  4.70it/s]\u001b[A\n",
      " 19%|█▊        | 117/625 [00:23<01:48,  4.70it/s]\u001b[A\n",
      " 19%|█▉        | 118/625 [00:23<01:47,  4.71it/s]\u001b[A\n",
      " 19%|█▉        | 119/625 [00:24<01:47,  4.71it/s]\u001b[A\n",
      " 19%|█▉        | 120/625 [00:24<01:47,  4.71it/s]\u001b[A\n",
      " 19%|█▉        | 121/625 [00:24<01:47,  4.71it/s]\u001b[A\n",
      " 20%|█▉        | 122/625 [00:24<01:46,  4.71it/s]\u001b[A\n",
      " 20%|█▉        | 123/625 [00:25<01:47,  4.67it/s]\u001b[A\n",
      " 20%|█▉        | 124/625 [00:25<01:47,  4.68it/s]\u001b[A\n",
      " 20%|██        | 125/625 [00:25<01:47,  4.67it/s]\u001b[A\n",
      " 20%|██        | 126/625 [00:25<01:46,  4.68it/s]\u001b[A\n",
      " 20%|██        | 127/625 [00:25<01:46,  4.69it/s]\u001b[A\n",
      " 20%|██        | 128/625 [00:26<01:45,  4.69it/s]\u001b[A\n",
      " 21%|██        | 129/625 [00:26<01:46,  4.65it/s]\u001b[A\n",
      " 21%|██        | 130/625 [00:26<01:46,  4.66it/s]\u001b[A\n",
      " 21%|██        | 131/625 [00:26<01:46,  4.65it/s]\u001b[A\n",
      " 21%|██        | 132/625 [00:26<01:48,  4.55it/s]\u001b[A\n",
      " 21%|██▏       | 133/625 [00:27<01:50,  4.47it/s]\u001b[A\n",
      " 21%|██▏       | 134/625 [00:27<01:45,  4.66it/s]\u001b[A\n",
      " 22%|██▏       | 135/625 [00:27<01:42,  4.77it/s]\u001b[A\n",
      " 22%|██▏       | 136/625 [00:27<01:49,  4.45it/s]\u001b[A\n",
      " 22%|██▏       | 137/625 [00:28<01:54,  4.25it/s]\u001b[A\n",
      " 22%|██▏       | 138/625 [00:28<01:48,  4.49it/s]\u001b[A\n",
      " 22%|██▏       | 139/625 [00:28<01:41,  4.79it/s]\u001b[A\n",
      " 22%|██▏       | 140/625 [00:28<01:39,  4.86it/s]\u001b[A\n",
      " 23%|██▎       | 141/625 [00:28<01:53,  4.28it/s]\u001b[A\n",
      " 23%|██▎       | 142/625 [00:29<01:53,  4.27it/s]\u001b[A\n",
      " 23%|██▎       | 143/625 [00:29<01:39,  4.82it/s]\u001b[A\n",
      " 23%|██▎       | 144/625 [00:29<01:36,  4.96it/s]\u001b[A\n",
      " 23%|██▎       | 145/625 [00:29<01:38,  4.89it/s]\u001b[A\n",
      " 23%|██▎       | 146/625 [00:29<01:40,  4.77it/s]\u001b[A\n",
      " 24%|██▎       | 147/625 [00:30<01:41,  4.72it/s]\u001b[A\n",
      " 24%|██▎       | 148/625 [00:30<01:40,  4.75it/s]\u001b[A\n",
      " 24%|██▍       | 149/625 [00:30<01:39,  4.78it/s]\u001b[A\n",
      " 24%|██▍       | 150/625 [00:30<01:40,  4.70it/s]\u001b[A\n",
      " 24%|██▍       | 151/625 [00:31<01:40,  4.71it/s]\u001b[A\n",
      " 24%|██▍       | 152/625 [00:31<01:40,  4.72it/s]\u001b[A\n",
      " 24%|██▍       | 153/625 [00:31<01:39,  4.76it/s]\u001b[A\n",
      " 25%|██▍       | 154/625 [00:31<01:38,  4.78it/s]\u001b[A\n",
      " 25%|██▍       | 155/625 [00:31<01:38,  4.75it/s]\u001b[A\n",
      " 25%|██▍       | 156/625 [00:32<01:39,  4.72it/s]\u001b[A\n",
      " 25%|██▌       | 157/625 [00:32<01:39,  4.73it/s]\u001b[A\n",
      " 25%|██▌       | 158/625 [00:32<01:37,  4.77it/s]\u001b[A\n",
      " 25%|██▌       | 159/625 [00:32<01:37,  4.79it/s]\u001b[A\n",
      " 26%|██▌       | 160/625 [00:32<01:37,  4.76it/s]\u001b[A\n",
      " 26%|██▌       | 161/625 [00:33<01:37,  4.75it/s]\u001b[A\n",
      " 26%|██▌       | 162/625 [00:33<01:37,  4.75it/s]\u001b[A\n",
      " 26%|██▌       | 163/625 [00:33<01:36,  4.77it/s]\u001b[A\n",
      " 26%|██▌       | 164/625 [00:33<01:36,  4.79it/s]\u001b[A\n",
      " 26%|██▋       | 165/625 [00:33<01:36,  4.78it/s]\u001b[A\n",
      " 27%|██▋       | 166/625 [00:34<01:36,  4.77it/s]\u001b[A\n",
      " 27%|██▋       | 167/625 [00:34<01:35,  4.78it/s]\u001b[A\n",
      " 27%|██▋       | 168/625 [00:34<01:34,  4.83it/s]\u001b[A\n",
      " 27%|██▋       | 169/625 [00:34<01:34,  4.84it/s]\u001b[A\n",
      " 27%|██▋       | 170/625 [00:34<01:34,  4.79it/s]\u001b[A\n",
      " 27%|██▋       | 171/625 [00:35<01:34,  4.79it/s]\u001b[A\n",
      " 28%|██▊       | 172/625 [00:35<01:34,  4.78it/s]\u001b[A\n",
      " 28%|██▊       | 173/625 [00:35<01:33,  4.81it/s]\u001b[A\n",
      " 28%|██▊       | 174/625 [00:35<01:33,  4.82it/s]\u001b[A\n",
      " 28%|██▊       | 175/625 [00:36<01:33,  4.81it/s]\u001b[A\n",
      " 28%|██▊       | 176/625 [00:36<01:33,  4.81it/s]\u001b[A\n",
      " 28%|██▊       | 177/625 [00:36<01:32,  4.82it/s]\u001b[A\n",
      " 28%|██▊       | 178/625 [00:36<01:32,  4.85it/s]\u001b[A\n",
      " 29%|██▊       | 179/625 [00:36<01:32,  4.84it/s]\u001b[A\n",
      " 29%|██▉       | 180/625 [00:37<01:32,  4.81it/s]\u001b[A\n",
      " 29%|██▉       | 181/625 [00:37<01:31,  4.83it/s]\u001b[A\n",
      " 29%|██▉       | 182/625 [00:37<01:31,  4.84it/s]\u001b[A\n",
      " 29%|██▉       | 183/625 [00:37<01:30,  4.87it/s]\u001b[A\n",
      " 29%|██▉       | 184/625 [00:37<01:30,  4.87it/s]\u001b[A\n",
      " 30%|██▉       | 185/625 [00:38<01:30,  4.84it/s]\u001b[A\n",
      " 30%|██▉       | 186/625 [00:38<01:30,  4.84it/s]\u001b[A\n",
      " 30%|██▉       | 187/625 [00:38<01:29,  4.87it/s]\u001b[A\n",
      " 30%|███       | 188/625 [00:38<01:29,  4.89it/s]\u001b[A\n",
      " 30%|███       | 189/625 [00:38<01:29,  4.87it/s]\u001b[A\n",
      " 30%|███       | 190/625 [00:39<01:29,  4.86it/s]\u001b[A\n",
      " 31%|███       | 191/625 [00:39<01:29,  4.84it/s]\u001b[A\n",
      " 31%|███       | 192/625 [00:39<01:29,  4.82it/s]\u001b[A\n",
      " 31%|███       | 193/625 [00:39<01:28,  4.87it/s]\u001b[A\n",
      " 31%|███       | 194/625 [00:39<01:28,  4.88it/s]\u001b[A\n",
      " 31%|███       | 195/625 [00:40<01:28,  4.87it/s]\u001b[A\n",
      " 31%|███▏      | 196/625 [00:40<01:28,  4.85it/s]\u001b[A\n",
      " 32%|███▏      | 197/625 [00:40<01:27,  4.87it/s]\u001b[A\n",
      " 32%|███▏      | 198/625 [00:40<01:27,  4.87it/s]\u001b[A\n",
      " 32%|███▏      | 199/625 [00:40<01:28,  4.84it/s]\u001b[A\n",
      " 32%|███▏      | 200/625 [00:41<01:27,  4.88it/s]\u001b[A\n",
      " 32%|███▏      | 201/625 [00:41<01:27,  4.84it/s]\u001b[A\n",
      " 32%|███▏      | 202/625 [00:41<01:25,  4.93it/s]\u001b[A\n",
      " 32%|███▏      | 203/625 [00:41<01:25,  4.92it/s]\u001b[A\n",
      " 33%|███▎      | 204/625 [00:41<01:25,  4.93it/s]\u001b[A\n",
      " 33%|███▎      | 205/625 [00:42<01:25,  4.93it/s]\u001b[A\n",
      " 33%|███▎      | 206/625 [00:42<01:25,  4.89it/s]\u001b[A\n",
      " 33%|███▎      | 207/625 [00:42<01:25,  4.88it/s]\u001b[A\n",
      " 33%|███▎      | 208/625 [00:42<01:25,  4.90it/s]\u001b[A\n",
      " 33%|███▎      | 209/625 [00:43<01:24,  4.90it/s]\u001b[A\n",
      " 34%|███▎      | 210/625 [00:43<01:24,  4.89it/s]\u001b[A\n",
      " 34%|███▍      | 211/625 [00:43<01:24,  4.92it/s]\u001b[A\n",
      " 34%|███▍      | 212/625 [00:43<01:23,  4.94it/s]\u001b[A\n",
      " 34%|███▍      | 213/625 [00:43<01:23,  4.93it/s]\u001b[A\n",
      " 34%|███▍      | 214/625 [00:44<01:22,  4.97it/s]\u001b[A\n",
      " 34%|███▍      | 215/625 [00:44<01:22,  4.97it/s]\u001b[A\n",
      " 35%|███▍      | 216/625 [00:44<01:22,  4.97it/s]\u001b[A\n",
      " 35%|███▍      | 217/625 [00:44<01:22,  4.96it/s]\u001b[A\n",
      " 35%|███▍      | 218/625 [00:44<01:22,  4.96it/s]\u001b[A\n",
      " 35%|███▌      | 219/625 [00:45<01:22,  4.94it/s]\u001b[A\n",
      " 35%|███▌      | 220/625 [00:45<01:21,  4.96it/s]\u001b[A\n",
      " 35%|███▌      | 221/625 [00:45<01:21,  4.95it/s]\u001b[A\n",
      " 36%|███▌      | 222/625 [00:45<01:21,  4.94it/s]\u001b[A\n",
      " 36%|███▌      | 223/625 [00:45<01:21,  4.96it/s]\u001b[A\n",
      " 36%|███▌      | 224/625 [00:46<01:21,  4.92it/s]\u001b[A\n",
      " 36%|███▌      | 225/625 [00:46<01:20,  4.97it/s]\u001b[A\n",
      " 36%|███▌      | 226/625 [00:46<01:20,  4.96it/s]\u001b[A\n",
      " 36%|███▋      | 227/625 [00:46<01:20,  4.96it/s]\u001b[A\n",
      " 36%|███▋      | 228/625 [00:46<01:20,  4.96it/s]\u001b[A\n",
      " 37%|███▋      | 229/625 [00:47<01:19,  4.95it/s]\u001b[A\n",
      " 37%|███▋      | 230/625 [00:47<01:19,  4.94it/s]\u001b[A\n",
      " 37%|███▋      | 231/625 [00:47<01:19,  4.96it/s]\u001b[A\n",
      " 37%|███▋      | 232/625 [00:47<01:19,  4.96it/s]\u001b[A\n",
      " 37%|███▋      | 233/625 [00:47<01:18,  4.97it/s]\u001b[A\n",
      " 37%|███▋      | 234/625 [00:48<01:19,  4.95it/s]\u001b[A\n",
      " 38%|███▊      | 235/625 [00:48<01:18,  4.95it/s]\u001b[A\n",
      " 38%|███▊      | 236/625 [00:48<01:18,  4.96it/s]\u001b[A\n",
      " 38%|███▊      | 237/625 [00:48<01:18,  4.96it/s]\u001b[A\n",
      " 38%|███▊      | 238/625 [00:48<01:17,  4.97it/s]\u001b[A\n",
      " 38%|███▊      | 239/625 [00:49<01:18,  4.95it/s]\u001b[A\n",
      " 38%|███▊      | 240/625 [00:49<01:18,  4.93it/s]\u001b[A\n",
      " 39%|███▊      | 241/625 [00:49<01:17,  4.94it/s]\u001b[A\n",
      " 39%|███▊      | 242/625 [00:49<01:17,  4.97it/s]\u001b[A\n",
      " 39%|███▉      | 243/625 [00:49<01:16,  4.97it/s]\u001b[A\n",
      " 39%|███▉      | 244/625 [00:50<01:16,  4.96it/s]\u001b[A\n",
      " 39%|███▉      | 245/625 [00:50<01:16,  4.96it/s]\u001b[A\n",
      " 39%|███▉      | 246/625 [00:50<01:16,  4.96it/s]\u001b[A\n",
      " 40%|███▉      | 247/625 [00:50<01:16,  4.97it/s]\u001b[A\n",
      " 40%|███▉      | 248/625 [00:50<01:15,  4.97it/s]\u001b[A\n",
      " 40%|███▉      | 249/625 [00:51<01:16,  4.93it/s]\u001b[A\n",
      " 40%|████      | 250/625 [00:51<01:15,  4.97it/s]\u001b[A\n",
      " 40%|████      | 251/625 [00:51<01:15,  4.97it/s]\u001b[A\n",
      " 40%|████      | 252/625 [00:51<01:15,  4.95it/s]\u001b[A\n",
      " 40%|████      | 253/625 [00:51<01:14,  4.97it/s]\u001b[A\n",
      " 41%|████      | 254/625 [00:52<01:14,  4.98it/s]\u001b[A\n",
      " 41%|████      | 255/625 [00:52<01:13,  5.01it/s]\u001b[A\n",
      " 41%|████      | 256/625 [00:52<01:13,  5.02it/s]\u001b[A\n",
      " 41%|████      | 257/625 [00:52<01:13,  5.01it/s]\u001b[A\n",
      " 41%|████▏     | 258/625 [00:52<01:13,  5.02it/s]\u001b[A\n",
      " 41%|████▏     | 259/625 [00:53<01:13,  5.01it/s]\u001b[A\n",
      " 42%|████▏     | 260/625 [00:53<01:13,  5.00it/s]\u001b[A\n",
      " 42%|████▏     | 261/625 [00:53<01:13,  4.93it/s]\u001b[A\n",
      " 42%|████▏     | 262/625 [00:53<01:12,  5.01it/s]\u001b[A\n",
      " 42%|████▏     | 263/625 [00:53<01:11,  5.04it/s]\u001b[A\n",
      " 42%|████▏     | 264/625 [00:54<01:11,  5.02it/s]\u001b[A\n",
      " 42%|████▏     | 265/625 [00:54<01:11,  5.01it/s]\u001b[A\n",
      " 43%|████▎     | 266/625 [00:54<01:11,  5.01it/s]\u001b[A\n",
      " 43%|████▎     | 267/625 [00:54<01:11,  4.99it/s]\u001b[A\n",
      " 43%|████▎     | 268/625 [00:54<01:11,  4.97it/s]\u001b[A\n",
      " 43%|████▎     | 269/625 [00:55<01:11,  5.01it/s]\u001b[A\n",
      " 43%|████▎     | 270/625 [00:55<01:10,  5.05it/s]\u001b[A\n",
      " 43%|████▎     | 271/625 [00:55<01:10,  5.00it/s]\u001b[A\n",
      " 44%|████▎     | 272/625 [00:55<01:10,  5.04it/s]\u001b[A\n",
      " 44%|████▎     | 273/625 [00:55<01:09,  5.03it/s]\u001b[A\n",
      " 44%|████▍     | 274/625 [00:56<01:09,  5.02it/s]\u001b[A\n",
      " 44%|████▍     | 275/625 [00:56<01:09,  5.02it/s]\u001b[A\n",
      " 44%|████▍     | 276/625 [00:56<01:08,  5.06it/s]\u001b[A\n",
      " 44%|████▍     | 277/625 [00:56<01:09,  5.00it/s]\u001b[A\n",
      " 44%|████▍     | 278/625 [00:56<01:09,  5.01it/s]\u001b[A\n",
      " 45%|████▍     | 279/625 [00:57<01:08,  5.04it/s]\u001b[A\n",
      " 45%|████▍     | 280/625 [00:57<01:08,  5.05it/s]\u001b[A\n",
      " 45%|████▍     | 281/625 [00:57<01:07,  5.09it/s]\u001b[A\n",
      " 45%|████▌     | 282/625 [00:57<01:07,  5.06it/s]\u001b[A\n",
      " 45%|████▌     | 283/625 [00:57<01:07,  5.06it/s]\u001b[A\n",
      " 45%|████▌     | 284/625 [00:58<01:07,  5.06it/s]\u001b[A\n",
      " 46%|████▌     | 285/625 [00:58<01:07,  5.07it/s]\u001b[A\n",
      " 46%|████▌     | 286/625 [00:58<01:06,  5.09it/s]\u001b[A\n",
      " 46%|████▌     | 287/625 [00:58<01:06,  5.07it/s]\u001b[A\n",
      " 46%|████▌     | 288/625 [00:58<01:06,  5.07it/s]\u001b[A\n",
      " 46%|████▌     | 289/625 [00:59<01:05,  5.13it/s]\u001b[A\n",
      " 46%|████▋     | 290/625 [00:59<01:05,  5.09it/s]\u001b[A\n",
      " 47%|████▋     | 291/625 [00:59<01:06,  5.06it/s]\u001b[A\n",
      " 47%|████▋     | 292/625 [00:59<01:05,  5.08it/s]\u001b[A\n",
      " 47%|████▋     | 293/625 [00:59<01:05,  5.04it/s]\u001b[A\n",
      " 47%|████▋     | 294/625 [01:00<01:04,  5.10it/s]\u001b[A\n",
      " 47%|████▋     | 295/625 [01:00<01:05,  5.05it/s]\u001b[A\n",
      " 47%|████▋     | 296/625 [01:00<01:05,  5.05it/s]\u001b[A\n",
      " 48%|████▊     | 297/625 [01:00<01:04,  5.11it/s]\u001b[A\n",
      " 48%|████▊     | 298/625 [01:00<01:04,  5.10it/s]\u001b[A\n",
      " 48%|████▊     | 299/625 [01:01<01:03,  5.10it/s]\u001b[A\n",
      " 48%|████▊     | 300/625 [01:01<01:03,  5.10it/s]\u001b[A\n",
      " 48%|████▊     | 301/625 [01:01<01:03,  5.09it/s]\u001b[A\n",
      " 48%|████▊     | 302/625 [01:01<01:03,  5.09it/s]\u001b[A\n",
      " 48%|████▊     | 303/625 [01:01<01:02,  5.11it/s]\u001b[A\n",
      " 49%|████▊     | 304/625 [01:01<01:03,  5.08it/s]\u001b[A\n",
      " 49%|████▉     | 305/625 [01:02<01:02,  5.11it/s]\u001b[A\n",
      " 49%|████▉     | 306/625 [01:02<01:02,  5.10it/s]\u001b[A\n",
      " 49%|████▉     | 307/625 [01:02<01:02,  5.11it/s]\u001b[A\n",
      " 49%|████▉     | 308/625 [01:02<01:01,  5.12it/s]\u001b[A\n",
      " 49%|████▉     | 309/625 [01:02<01:01,  5.13it/s]\u001b[A\n",
      " 50%|████▉     | 310/625 [01:03<01:01,  5.12it/s]\u001b[A\n",
      " 50%|████▉     | 311/625 [01:03<01:01,  5.08it/s]\u001b[A\n",
      " 50%|████▉     | 312/625 [01:03<01:01,  5.09it/s]\u001b[A\n",
      " 50%|█████     | 313/625 [01:03<01:01,  5.11it/s]\u001b[A\n",
      " 50%|█████     | 314/625 [01:03<01:01,  5.07it/s]\u001b[A\n",
      " 50%|█████     | 315/625 [01:04<01:00,  5.12it/s]\u001b[A\n",
      " 51%|█████     | 316/625 [01:04<01:00,  5.12it/s]\u001b[A\n",
      " 51%|█████     | 317/625 [01:04<01:00,  5.06it/s]\u001b[A\n",
      " 51%|█████     | 318/625 [01:04<01:00,  5.12it/s]\u001b[A\n",
      " 51%|█████     | 319/625 [01:04<00:59,  5.13it/s]\u001b[A\n",
      " 51%|█████     | 320/625 [01:05<00:59,  5.13it/s]\u001b[A\n",
      " 51%|█████▏    | 321/625 [01:05<00:59,  5.10it/s]\u001b[A\n",
      " 52%|█████▏    | 322/625 [01:05<00:59,  5.12it/s]\u001b[A\n",
      " 52%|█████▏    | 323/625 [01:05<00:59,  5.12it/s]\u001b[A\n",
      " 52%|█████▏    | 324/625 [01:05<00:58,  5.11it/s]\u001b[A\n",
      " 52%|█████▏    | 325/625 [01:06<00:58,  5.15it/s]\u001b[A\n",
      " 52%|█████▏    | 326/625 [01:06<00:58,  5.12it/s]\u001b[A\n",
      " 52%|█████▏    | 327/625 [01:06<00:58,  5.11it/s]\u001b[A\n",
      " 52%|█████▏    | 328/625 [01:06<00:57,  5.13it/s]\u001b[A\n",
      " 53%|█████▎    | 329/625 [01:06<00:57,  5.14it/s]\u001b[A\n",
      " 53%|█████▎    | 330/625 [01:07<00:57,  5.11it/s]\u001b[A\n",
      " 53%|█████▎    | 331/625 [01:07<00:57,  5.13it/s]\u001b[A\n",
      " 53%|█████▎    | 332/625 [01:07<00:57,  5.10it/s]\u001b[A\n",
      " 53%|█████▎    | 333/625 [01:07<00:57,  5.12it/s]\u001b[A\n",
      " 53%|█████▎    | 334/625 [01:07<00:56,  5.15it/s]\u001b[A\n",
      " 54%|█████▎    | 335/625 [01:08<00:56,  5.11it/s]\u001b[A\n",
      " 54%|█████▍    | 336/625 [01:08<00:56,  5.11it/s]\u001b[A\n",
      " 54%|█████▍    | 337/625 [01:08<00:56,  5.14it/s]\u001b[A\n",
      " 54%|█████▍    | 338/625 [01:08<00:55,  5.13it/s]\u001b[A\n",
      " 54%|█████▍    | 339/625 [01:08<00:55,  5.14it/s]\u001b[A\n",
      " 54%|█████▍    | 340/625 [01:09<00:55,  5.09it/s]\u001b[A\n",
      " 55%|█████▍    | 341/625 [01:09<00:55,  5.10it/s]\u001b[A\n",
      " 55%|█████▍    | 342/625 [01:09<00:55,  5.11it/s]\u001b[A\n",
      " 55%|█████▍    | 343/625 [01:09<00:54,  5.14it/s]\u001b[A\n",
      " 55%|█████▌    | 344/625 [01:09<00:54,  5.13it/s]\u001b[A\n",
      " 55%|█████▌    | 345/625 [01:09<00:54,  5.15it/s]\u001b[A\n",
      " 55%|█████▌    | 346/625 [01:10<00:54,  5.13it/s]\u001b[A\n",
      " 56%|█████▌    | 347/625 [01:10<00:54,  5.11it/s]\u001b[A\n",
      " 56%|█████▌    | 348/625 [01:10<00:54,  5.10it/s]\u001b[A\n",
      " 56%|█████▌    | 349/625 [01:10<00:54,  5.09it/s]\u001b[A\n",
      " 56%|█████▌    | 350/625 [01:10<00:53,  5.11it/s]\u001b[A\n",
      " 56%|█████▌    | 351/625 [01:11<00:53,  5.12it/s]\u001b[A\n",
      " 56%|█████▋    | 352/625 [01:11<00:53,  5.09it/s]\u001b[A\n",
      " 56%|█████▋    | 353/625 [01:11<00:53,  5.12it/s]\u001b[A\n",
      " 57%|█████▋    | 354/625 [01:11<00:52,  5.13it/s]\u001b[A\n",
      " 57%|█████▋    | 355/625 [01:11<00:52,  5.14it/s]\u001b[A\n",
      " 57%|█████▋    | 356/625 [01:12<00:52,  5.14it/s]\u001b[A\n",
      " 57%|█████▋    | 357/625 [01:12<00:51,  5.16it/s]\u001b[A\n",
      " 57%|█████▋    | 358/625 [01:12<00:52,  5.13it/s]\u001b[A\n",
      " 57%|█████▋    | 359/625 [01:12<00:51,  5.16it/s]\u001b[A\n",
      " 58%|█████▊    | 360/625 [01:12<00:51,  5.14it/s]\u001b[A\n",
      " 58%|█████▊    | 361/625 [01:13<00:51,  5.10it/s]\u001b[A\n",
      " 58%|█████▊    | 362/625 [01:13<00:51,  5.14it/s]\u001b[A\n",
      " 58%|█████▊    | 363/625 [01:13<00:50,  5.16it/s]\u001b[A\n",
      " 58%|█████▊    | 364/625 [01:13<00:50,  5.17it/s]\u001b[A\n",
      " 58%|█████▊    | 365/625 [01:13<00:50,  5.16it/s]\u001b[A\n",
      " 59%|█████▊    | 366/625 [01:14<00:50,  5.14it/s]\u001b[A\n",
      " 59%|█████▊    | 367/625 [01:14<00:50,  5.16it/s]\u001b[A\n",
      " 59%|█████▉    | 368/625 [01:14<00:50,  5.14it/s]\u001b[A\n",
      " 59%|█████▉    | 369/625 [01:14<00:49,  5.13it/s]\u001b[A\n",
      " 59%|█████▉    | 370/625 [01:14<00:49,  5.16it/s]\u001b[A\n",
      " 59%|█████▉    | 371/625 [01:15<00:49,  5.14it/s]\u001b[A\n",
      " 60%|█████▉    | 372/625 [01:15<00:49,  5.13it/s]\u001b[A\n",
      " 60%|█████▉    | 373/625 [01:15<00:49,  5.14it/s]\u001b[A\n",
      " 60%|█████▉    | 374/625 [01:15<00:48,  5.13it/s]\u001b[A\n",
      " 60%|██████    | 375/625 [01:15<00:48,  5.14it/s]\u001b[A\n",
      " 60%|██████    | 376/625 [01:16<00:48,  5.14it/s]\u001b[A\n",
      " 60%|██████    | 377/625 [01:16<00:48,  5.12it/s]\u001b[A\n",
      " 60%|██████    | 378/625 [01:16<00:48,  5.09it/s]\u001b[A\n",
      " 61%|██████    | 379/625 [01:16<00:47,  5.16it/s]\u001b[A\n",
      " 61%|██████    | 380/625 [01:16<00:47,  5.14it/s]\u001b[A\n",
      " 61%|██████    | 381/625 [01:17<00:47,  5.15it/s]\u001b[A\n",
      " 61%|██████    | 382/625 [01:17<00:47,  5.13it/s]\u001b[A\n",
      " 61%|██████▏   | 383/625 [01:17<00:47,  5.12it/s]\u001b[A\n",
      " 61%|██████▏   | 384/625 [01:17<00:46,  5.14it/s]\u001b[A\n",
      " 62%|██████▏   | 385/625 [01:17<00:46,  5.12it/s]\u001b[A\n",
      " 62%|██████▏   | 386/625 [01:17<00:46,  5.13it/s]\u001b[A\n",
      " 62%|██████▏   | 387/625 [01:18<00:46,  5.15it/s]\u001b[A\n",
      " 62%|██████▏   | 388/625 [01:18<00:46,  5.12it/s]\u001b[A\n",
      " 62%|██████▏   | 389/625 [01:18<00:45,  5.13it/s]\u001b[A\n",
      " 62%|██████▏   | 390/625 [01:18<00:45,  5.16it/s]\u001b[A\n",
      " 63%|██████▎   | 391/625 [01:18<00:45,  5.14it/s]\u001b[A\n",
      " 63%|██████▎   | 392/625 [01:19<00:45,  5.17it/s]\u001b[A\n",
      " 63%|██████▎   | 393/625 [01:19<00:45,  5.13it/s]\u001b[A\n",
      " 63%|██████▎   | 394/625 [01:19<00:44,  5.14it/s]\u001b[A\n",
      " 63%|██████▎   | 395/625 [01:19<00:44,  5.14it/s]\u001b[A\n",
      " 63%|██████▎   | 396/625 [01:19<00:44,  5.11it/s]\u001b[A\n",
      " 64%|██████▎   | 397/625 [01:20<00:44,  5.12it/s]\u001b[A\n",
      " 64%|██████▎   | 398/625 [01:20<00:44,  5.14it/s]\u001b[A\n",
      " 64%|██████▍   | 399/625 [01:20<00:44,  5.11it/s]\u001b[A\n",
      " 64%|██████▍   | 400/625 [01:20<00:43,  5.12it/s]\u001b[A\n",
      " 64%|██████▍   | 401/625 [01:20<00:43,  5.13it/s]\u001b[A\n",
      " 64%|██████▍   | 402/625 [01:21<00:43,  5.15it/s]\u001b[A\n",
      " 64%|██████▍   | 403/625 [01:21<00:43,  5.16it/s]\u001b[A\n",
      " 65%|██████▍   | 404/625 [01:21<00:42,  5.14it/s]\u001b[A\n",
      " 65%|██████▍   | 405/625 [01:21<00:42,  5.13it/s]\u001b[A\n",
      " 65%|██████▍   | 406/625 [01:21<00:42,  5.14it/s]\u001b[A\n",
      " 65%|██████▌   | 407/625 [01:22<00:42,  5.13it/s]\u001b[A\n",
      " 65%|██████▌   | 408/625 [01:22<00:42,  5.14it/s]\u001b[A\n",
      " 65%|██████▌   | 409/625 [01:22<00:41,  5.16it/s]\u001b[A\n",
      " 66%|██████▌   | 410/625 [01:22<00:41,  5.13it/s]\u001b[A\n",
      " 66%|██████▌   | 411/625 [01:22<00:41,  5.13it/s]\u001b[A\n",
      " 66%|██████▌   | 412/625 [01:23<00:41,  5.11it/s]\u001b[A\n",
      " 66%|██████▌   | 413/625 [01:23<00:41,  5.13it/s]\u001b[A\n",
      " 66%|██████▌   | 414/625 [01:23<00:41,  5.07it/s]\u001b[A\n",
      " 66%|██████▋   | 415/625 [01:23<00:41,  5.09it/s]\u001b[A\n",
      " 67%|██████▋   | 416/625 [01:23<00:40,  5.12it/s]\u001b[A\n",
      " 67%|██████▋   | 417/625 [01:24<00:40,  5.13it/s]\u001b[A\n",
      " 67%|██████▋   | 418/625 [01:24<00:40,  5.12it/s]\u001b[A\n",
      " 67%|██████▋   | 419/625 [01:24<00:40,  5.12it/s]\u001b[A\n",
      " 67%|██████▋   | 420/625 [01:24<00:40,  5.11it/s]\u001b[A\n",
      " 67%|██████▋   | 421/625 [01:24<00:39,  5.14it/s]\u001b[A\n",
      " 68%|██████▊   | 422/625 [01:25<00:40,  5.07it/s]\u001b[A\n",
      " 68%|██████▊   | 423/625 [01:25<00:39,  5.08it/s]\u001b[A\n",
      " 68%|██████▊   | 424/625 [01:25<00:39,  5.14it/s]\u001b[A\n",
      " 68%|██████▊   | 425/625 [01:25<00:40,  4.94it/s]\u001b[A\n",
      " 68%|██████▊   | 426/625 [01:25<00:38,  5.12it/s]\u001b[A\n",
      " 68%|██████▊   | 427/625 [01:25<00:38,  5.15it/s]\u001b[A\n",
      " 68%|██████▊   | 428/625 [01:26<00:38,  5.11it/s]\u001b[A\n",
      " 69%|██████▊   | 429/625 [01:26<00:38,  5.09it/s]\u001b[A\n",
      " 69%|██████▉   | 430/625 [01:26<00:37,  5.14it/s]\u001b[A\n",
      " 69%|██████▉   | 431/625 [01:26<00:38,  5.05it/s]\u001b[A\n",
      " 69%|██████▉   | 432/625 [01:26<00:37,  5.11it/s]\u001b[A\n",
      " 69%|██████▉   | 433/625 [01:27<00:37,  5.16it/s]\u001b[A\n",
      " 69%|██████▉   | 434/625 [01:27<00:37,  5.14it/s]\u001b[A\n",
      " 70%|██████▉   | 435/625 [01:27<00:37,  5.11it/s]\u001b[A\n",
      " 70%|██████▉   | 436/625 [01:27<00:37,  5.08it/s]\u001b[A\n",
      " 70%|██████▉   | 437/625 [01:27<00:36,  5.13it/s]\u001b[A\n",
      " 70%|███████   | 438/625 [01:28<00:36,  5.13it/s]\u001b[A\n",
      " 70%|███████   | 439/625 [01:28<00:36,  5.14it/s]\u001b[A\n",
      " 70%|███████   | 440/625 [01:28<00:36,  5.13it/s]\u001b[A\n",
      " 71%|███████   | 441/625 [01:28<00:36,  5.09it/s]\u001b[A\n",
      " 71%|███████   | 442/625 [01:28<00:35,  5.09it/s]\u001b[A\n",
      " 71%|███████   | 443/625 [01:29<00:35,  5.16it/s]\u001b[A\n",
      " 71%|███████   | 444/625 [01:29<00:35,  5.13it/s]\u001b[A\n",
      " 71%|███████   | 445/625 [01:29<00:35,  5.07it/s]\u001b[A\n",
      " 71%|███████▏  | 446/625 [01:29<00:35,  5.11it/s]\u001b[A\n",
      " 72%|███████▏  | 447/625 [01:29<00:35,  5.06it/s]\u001b[A\n",
      " 72%|███████▏  | 448/625 [01:30<00:34,  5.12it/s]\u001b[A\n",
      " 72%|███████▏  | 449/625 [01:30<00:34,  5.13it/s]\u001b[A\n",
      " 72%|███████▏  | 450/625 [01:30<00:34,  5.09it/s]\u001b[A\n",
      " 72%|███████▏  | 451/625 [01:30<00:34,  5.10it/s]\u001b[A\n",
      " 72%|███████▏  | 452/625 [01:30<00:34,  5.06it/s]\u001b[A\n",
      " 72%|███████▏  | 453/625 [01:31<00:33,  5.09it/s]\u001b[A\n",
      " 73%|███████▎  | 454/625 [01:31<00:33,  5.10it/s]\u001b[A\n",
      " 73%|███████▎  | 455/625 [01:31<00:33,  5.08it/s]\u001b[A\n",
      " 73%|███████▎  | 456/625 [01:31<00:33,  5.07it/s]\u001b[A\n",
      " 73%|███████▎  | 457/625 [01:31<00:33,  5.06it/s]\u001b[A\n",
      " 73%|███████▎  | 458/625 [01:32<00:32,  5.08it/s]\u001b[A\n",
      " 73%|███████▎  | 459/625 [01:32<00:32,  5.08it/s]\u001b[A\n",
      " 74%|███████▎  | 460/625 [01:32<00:32,  5.08it/s]\u001b[A\n",
      " 74%|███████▍  | 461/625 [01:32<00:32,  5.05it/s]\u001b[A\n",
      " 74%|███████▍  | 462/625 [01:32<00:32,  5.06it/s]\u001b[A\n",
      " 74%|███████▍  | 463/625 [01:33<00:31,  5.08it/s]\u001b[A\n",
      " 74%|███████▍  | 464/625 [01:33<00:31,  5.08it/s]\u001b[A\n",
      " 74%|███████▍  | 465/625 [01:33<00:31,  5.06it/s]\u001b[A\n",
      " 75%|███████▍  | 466/625 [01:33<00:31,  5.06it/s]\u001b[A\n",
      " 75%|███████▍  | 467/625 [01:33<00:31,  5.06it/s]\u001b[A\n",
      " 75%|███████▍  | 468/625 [01:34<00:31,  5.06it/s]\u001b[A\n",
      " 75%|███████▌  | 469/625 [01:34<00:30,  5.07it/s]\u001b[A\n",
      " 75%|███████▌  | 470/625 [01:34<00:30,  5.05it/s]\u001b[A\n",
      " 75%|███████▌  | 471/625 [01:34<00:30,  5.06it/s]\u001b[A\n",
      " 76%|███████▌  | 472/625 [01:34<00:30,  5.07it/s]\u001b[A\n",
      " 76%|███████▌  | 473/625 [01:35<00:30,  5.02it/s]\u001b[A\n",
      " 76%|███████▌  | 474/625 [01:35<00:29,  5.08it/s]\u001b[A\n",
      " 76%|███████▌  | 475/625 [01:35<00:29,  5.06it/s]\u001b[A\n",
      " 76%|███████▌  | 476/625 [01:35<00:29,  5.07it/s]\u001b[A\n",
      " 76%|███████▋  | 477/625 [01:35<00:29,  5.08it/s]\u001b[A\n",
      " 76%|███████▋  | 478/625 [01:36<00:29,  5.06it/s]\u001b[A\n",
      " 77%|███████▋  | 479/625 [01:36<00:28,  5.07it/s]\u001b[A\n",
      " 77%|███████▋  | 480/625 [01:36<00:28,  5.06it/s]\u001b[A\n",
      " 77%|███████▋  | 481/625 [01:36<00:28,  5.06it/s]\u001b[A\n",
      " 77%|███████▋  | 482/625 [01:36<00:28,  5.06it/s]\u001b[A\n",
      " 77%|███████▋  | 483/625 [01:37<00:28,  5.06it/s]\u001b[A\n",
      " 77%|███████▋  | 484/625 [01:37<00:27,  5.04it/s]\u001b[A\n",
      " 78%|███████▊  | 485/625 [01:37<00:27,  5.03it/s]\u001b[A\n",
      " 78%|███████▊  | 486/625 [01:37<00:27,  5.05it/s]\u001b[A\n",
      " 78%|███████▊  | 487/625 [01:37<00:27,  5.06it/s]\u001b[A\n",
      " 78%|███████▊  | 488/625 [01:37<00:27,  5.06it/s]\u001b[A\n",
      " 78%|███████▊  | 489/625 [01:38<00:26,  5.04it/s]\u001b[A\n",
      " 78%|███████▊  | 490/625 [01:38<00:26,  5.02it/s]\u001b[A\n",
      " 79%|███████▊  | 491/625 [01:38<00:26,  5.02it/s]\u001b[A\n",
      " 79%|███████▊  | 492/625 [01:38<00:26,  5.04it/s]\u001b[A\n",
      " 79%|███████▉  | 493/625 [01:38<00:26,  5.05it/s]\u001b[A\n",
      " 79%|███████▉  | 494/625 [01:39<00:26,  5.00it/s]\u001b[A\n",
      " 79%|███████▉  | 495/625 [01:39<00:26,  4.97it/s]\u001b[A\n",
      " 79%|███████▉  | 496/625 [01:39<00:25,  5.00it/s]\u001b[A\n",
      " 80%|███████▉  | 497/625 [01:39<00:25,  4.98it/s]\u001b[A\n",
      " 80%|███████▉  | 498/625 [01:39<00:25,  5.00it/s]\u001b[A\n",
      " 80%|███████▉  | 499/625 [01:40<00:25,  4.93it/s]\u001b[A\n",
      " 80%|████████  | 500/625 [01:40<00:24,  5.02it/s]\u001b[A\n",
      " 80%|████████  | 501/625 [01:40<00:24,  5.01it/s]\u001b[A\n",
      " 80%|████████  | 502/625 [01:40<00:24,  4.99it/s]\u001b[A\n",
      " 80%|████████  | 503/625 [01:40<00:24,  5.05it/s]\u001b[A\n",
      " 81%|████████  | 504/625 [01:41<00:24,  5.03it/s]\u001b[A\n",
      " 81%|████████  | 505/625 [01:41<00:24,  5.00it/s]\u001b[A\n",
      " 81%|████████  | 506/625 [01:41<00:23,  4.99it/s]\u001b[A\n",
      " 81%|████████  | 507/625 [01:41<00:23,  4.99it/s]\u001b[A\n",
      " 81%|████████▏ | 508/625 [01:41<00:23,  5.01it/s]\u001b[A\n",
      " 81%|████████▏ | 509/625 [01:42<00:23,  4.98it/s]\u001b[A\n",
      " 82%|████████▏ | 510/625 [01:42<00:23,  4.95it/s]\u001b[A\n",
      " 82%|████████▏ | 511/625 [01:42<00:22,  4.97it/s]\u001b[A\n",
      " 82%|████████▏ | 512/625 [01:42<00:22,  4.97it/s]\u001b[A\n",
      " 82%|████████▏ | 513/625 [01:43<00:22,  4.98it/s]\u001b[A\n",
      " 82%|████████▏ | 514/625 [01:43<00:22,  5.01it/s]\u001b[A\n",
      " 82%|████████▏ | 515/625 [01:43<00:22,  4.92it/s]\u001b[A\n",
      " 83%|████████▎ | 516/625 [01:43<00:21,  5.01it/s]\u001b[A\n",
      " 83%|████████▎ | 517/625 [01:43<00:21,  5.08it/s]\u001b[A\n",
      " 83%|████████▎ | 518/625 [01:43<00:21,  5.04it/s]\u001b[A\n",
      " 83%|████████▎ | 519/625 [01:44<00:21,  5.02it/s]\u001b[A\n",
      " 83%|████████▎ | 520/625 [01:44<00:20,  5.01it/s]\u001b[A\n",
      " 83%|████████▎ | 521/625 [01:44<00:20,  5.00it/s]\u001b[A\n",
      " 84%|████████▎ | 522/625 [01:44<00:20,  5.00it/s]\u001b[A\n",
      " 84%|████████▎ | 523/625 [01:45<00:20,  4.98it/s]\u001b[A\n",
      " 84%|████████▍ | 524/625 [01:45<00:20,  4.96it/s]\u001b[A\n",
      " 84%|████████▍ | 525/625 [01:45<00:20,  4.95it/s]\u001b[A\n",
      " 84%|████████▍ | 526/625 [01:45<00:19,  4.96it/s]\u001b[A\n",
      " 84%|████████▍ | 527/625 [01:45<00:19,  4.97it/s]\u001b[A\n",
      " 84%|████████▍ | 528/625 [01:46<00:19,  4.97it/s]\u001b[A\n",
      " 85%|████████▍ | 529/625 [01:46<00:19,  4.96it/s]\u001b[A\n",
      " 85%|████████▍ | 530/625 [01:46<00:19,  4.95it/s]\u001b[A\n",
      " 85%|████████▍ | 531/625 [01:46<00:18,  4.96it/s]\u001b[A\n",
      " 85%|████████▌ | 532/625 [01:46<00:18,  4.97it/s]\u001b[A\n",
      " 85%|████████▌ | 533/625 [01:47<00:18,  4.95it/s]\u001b[A\n",
      " 85%|████████▌ | 534/625 [01:47<00:18,  4.95it/s]\u001b[A\n",
      " 86%|████████▌ | 535/625 [01:47<00:18,  4.95it/s]\u001b[A\n",
      " 86%|████████▌ | 536/625 [01:47<00:17,  4.95it/s]\u001b[A\n",
      " 86%|████████▌ | 537/625 [01:47<00:17,  4.96it/s]\u001b[A\n",
      " 86%|████████▌ | 538/625 [01:48<00:17,  4.95it/s]\u001b[A\n",
      " 86%|████████▌ | 539/625 [01:48<00:17,  4.96it/s]\u001b[A\n",
      " 86%|████████▋ | 540/625 [01:48<00:17,  4.93it/s]\u001b[A\n",
      " 87%|████████▋ | 541/625 [01:48<00:16,  4.96it/s]\u001b[A\n",
      " 87%|████████▋ | 542/625 [01:48<00:16,  4.96it/s]\u001b[A\n",
      " 87%|████████▋ | 543/625 [01:49<00:16,  4.96it/s]\u001b[A\n",
      " 87%|████████▋ | 544/625 [01:49<00:16,  4.95it/s]\u001b[A\n",
      " 87%|████████▋ | 545/625 [01:49<00:16,  4.95it/s]\u001b[A\n",
      " 87%|████████▋ | 546/625 [01:49<00:15,  4.95it/s]\u001b[A\n",
      " 88%|████████▊ | 547/625 [01:49<00:15,  4.95it/s]\u001b[A\n",
      " 88%|████████▊ | 548/625 [01:50<00:15,  4.95it/s]\u001b[A\n",
      " 88%|████████▊ | 549/625 [01:50<00:15,  4.95it/s]\u001b[A\n",
      " 88%|████████▊ | 550/625 [01:50<00:15,  4.94it/s]\u001b[A\n",
      " 88%|████████▊ | 551/625 [01:50<00:14,  4.94it/s]\u001b[A\n",
      " 88%|████████▊ | 552/625 [01:50<00:14,  4.95it/s]\u001b[A\n",
      " 88%|████████▊ | 553/625 [01:51<00:14,  4.95it/s]\u001b[A\n",
      " 89%|████████▊ | 554/625 [01:51<00:14,  4.94it/s]\u001b[A\n",
      " 89%|████████▉ | 555/625 [01:51<00:14,  4.94it/s]\u001b[A\n",
      " 89%|████████▉ | 556/625 [01:51<00:13,  4.95it/s]\u001b[A\n",
      " 89%|████████▉ | 557/625 [01:51<00:13,  4.95it/s]\u001b[A\n",
      " 89%|████████▉ | 558/625 [01:52<00:13,  4.96it/s]\u001b[A\n",
      " 89%|████████▉ | 559/625 [01:52<00:13,  4.94it/s]\u001b[A\n",
      " 90%|████████▉ | 560/625 [01:52<00:13,  4.95it/s]\u001b[A\n",
      " 90%|████████▉ | 561/625 [01:52<00:12,  4.94it/s]\u001b[A\n",
      " 90%|████████▉ | 562/625 [01:52<00:12,  4.96it/s]\u001b[A\n",
      " 90%|█████████ | 563/625 [01:53<00:12,  4.95it/s]\u001b[A\n",
      " 90%|█████████ | 564/625 [01:53<00:12,  4.93it/s]\u001b[A\n",
      " 90%|█████████ | 565/625 [01:53<00:12,  4.94it/s]\u001b[A\n",
      " 91%|█████████ | 566/625 [01:53<00:12,  4.90it/s]\u001b[A\n",
      " 91%|█████████ | 567/625 [01:53<00:11,  4.93it/s]\u001b[A\n",
      " 91%|█████████ | 568/625 [01:54<00:11,  4.96it/s]\u001b[A\n",
      " 91%|█████████ | 569/625 [01:54<00:11,  4.93it/s]\u001b[A\n",
      " 91%|█████████ | 570/625 [01:54<00:11,  4.94it/s]\u001b[A\n",
      " 91%|█████████▏| 571/625 [01:54<00:10,  4.92it/s]\u001b[A\n",
      " 92%|█████████▏| 572/625 [01:54<00:10,  4.97it/s]\u001b[A\n",
      " 92%|█████████▏| 573/625 [01:55<00:10,  4.97it/s]\u001b[A\n",
      " 92%|█████████▏| 574/625 [01:55<00:10,  4.94it/s]\u001b[A\n",
      " 92%|█████████▏| 575/625 [01:55<00:10,  4.94it/s]\u001b[A\n",
      " 92%|█████████▏| 576/625 [01:55<00:09,  4.91it/s]\u001b[A\n",
      " 92%|█████████▏| 577/625 [01:55<00:09,  4.96it/s]\u001b[A\n",
      " 92%|█████████▏| 578/625 [01:56<00:09,  4.94it/s]\u001b[A\n",
      " 93%|█████████▎| 579/625 [01:56<00:09,  4.93it/s]\u001b[A\n",
      " 93%|█████████▎| 580/625 [01:56<00:09,  4.95it/s]\u001b[A\n",
      " 93%|█████████▎| 581/625 [01:56<00:08,  4.94it/s]\u001b[A\n",
      " 93%|█████████▎| 582/625 [01:56<00:08,  4.96it/s]\u001b[A\n",
      " 93%|█████████▎| 583/625 [01:57<00:08,  4.94it/s]\u001b[A\n",
      " 93%|█████████▎| 584/625 [01:57<00:08,  4.95it/s]\u001b[A\n",
      " 94%|█████████▎| 585/625 [01:57<00:08,  4.94it/s]\u001b[A\n",
      " 94%|█████████▍| 586/625 [01:57<00:07,  4.94it/s]\u001b[A\n",
      " 94%|█████████▍| 587/625 [01:57<00:07,  4.91it/s]\u001b[A\n",
      " 94%|█████████▍| 588/625 [01:58<00:07,  4.96it/s]\u001b[A\n",
      " 94%|█████████▍| 589/625 [01:58<00:07,  4.94it/s]\u001b[A\n",
      " 94%|█████████▍| 590/625 [01:58<00:07,  4.99it/s]\u001b[A\n",
      " 95%|█████████▍| 591/625 [01:58<00:06,  4.97it/s]\u001b[A\n",
      " 95%|█████████▍| 592/625 [01:58<00:06,  4.98it/s]\u001b[A\n",
      " 95%|█████████▍| 593/625 [01:59<00:06,  4.96it/s]\u001b[A\n",
      " 95%|█████████▌| 594/625 [01:59<00:06,  4.96it/s]\u001b[A\n",
      " 95%|█████████▌| 595/625 [01:59<00:06,  4.95it/s]\u001b[A\n",
      " 95%|█████████▌| 596/625 [01:59<00:05,  4.95it/s]\u001b[A\n",
      " 96%|█████████▌| 597/625 [01:59<00:05,  4.96it/s]\u001b[A\n",
      " 96%|█████████▌| 598/625 [02:00<00:05,  4.97it/s]\u001b[A\n",
      " 96%|█████████▌| 599/625 [02:00<00:05,  4.95it/s]\u001b[A\n",
      " 96%|█████████▌| 600/625 [02:00<00:05,  4.94it/s]\u001b[A\n",
      " 96%|█████████▌| 601/625 [02:00<00:04,  4.95it/s]\u001b[A\n",
      " 96%|█████████▋| 602/625 [02:00<00:04,  4.96it/s]\u001b[A\n",
      " 96%|█████████▋| 603/625 [02:01<00:04,  4.95it/s]\u001b[A\n",
      " 97%|█████████▋| 604/625 [02:01<00:04,  4.94it/s]\u001b[A\n",
      " 97%|█████████▋| 605/625 [02:01<00:04,  4.94it/s]\u001b[A\n",
      " 97%|█████████▋| 606/625 [02:01<00:03,  4.95it/s]\u001b[A\n",
      " 97%|█████████▋| 607/625 [02:01<00:03,  4.97it/s]\u001b[A\n",
      " 97%|█████████▋| 608/625 [02:02<00:03,  4.94it/s]\u001b[A\n",
      " 97%|█████████▋| 609/625 [02:02<00:03,  4.95it/s]\u001b[A\n",
      " 98%|█████████▊| 610/625 [02:02<00:03,  4.95it/s]\u001b[A\n",
      " 98%|█████████▊| 611/625 [02:02<00:02,  4.95it/s]\u001b[A\n",
      " 98%|█████████▊| 612/625 [02:02<00:02,  4.95it/s]\u001b[A\n",
      " 98%|█████████▊| 613/625 [02:03<00:02,  4.95it/s]\u001b[A\n",
      " 98%|█████████▊| 614/625 [02:03<00:02,  4.96it/s]\u001b[A\n",
      " 98%|█████████▊| 615/625 [02:03<00:02,  4.95it/s]\u001b[A\n",
      " 99%|█████████▊| 616/625 [02:03<00:01,  4.95it/s]\u001b[A\n",
      " 99%|█████████▊| 617/625 [02:04<00:01,  4.92it/s]\u001b[A\n",
      " 99%|█████████▉| 618/625 [02:04<00:01,  4.96it/s]\u001b[A\n",
      " 99%|█████████▉| 619/625 [02:04<00:01,  4.96it/s]\u001b[A\n",
      " 99%|█████████▉| 620/625 [02:04<00:01,  4.95it/s]\u001b[A\n",
      " 99%|█████████▉| 621/625 [02:04<00:00,  4.95it/s]\u001b[A\n",
      "100%|█████████▉| 622/625 [02:05<00:00,  4.95it/s]\u001b[A\n",
      "100%|█████████▉| 623/625 [02:05<00:00,  4.96it/s]\u001b[A\n",
      "100%|█████████▉| 624/625 [02:05<00:00,  4.97it/s]\u001b[A\n",
      "100%|██████████| 625/625 [02:05<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8310, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = module\n",
    "\n",
    "accuracy = evaluate_task(model, val_dataloader)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "max_cell_id": 35
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
